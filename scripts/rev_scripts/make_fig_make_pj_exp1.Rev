# Script: make_fig_make_pj_exp1.Rev
# Authors: Fabio K. Mendes (f.mendes@wustl.edu) & Sarah K. Swiston (sarah.k.swiston@wustl.edu)
# Date: Oct, 2023

# This script will:
# (1) Read in all features and epoch information,
# (2) Build the FIG model,
# (3) Build a string specifying a PhyloJunction script
#
# NOTE: Run this script from hawaiian_simulations/

#################
# Initial setup #
#################

loadPlugin("TensorPhylo")

# setting up paths
if (!exists("experiment_path")) exp_path = "experiment1/"
if (!exists("features_path"))   features_path = exp_path + "feature_summary.csv"
if (!exists("times_path"))      times_path = exp_path + "age_summary.csv"
if (!exists("pj_scripts_dir"))  pj_scripts_dir = exp_path + "pj_scripts/"
if (!exists("model_truth_dir"))  model_truth_dir = exp_path + "model_truth/"

# setting up FIG model quantities we may need to tweak
#
# base rate parameters
if (!exists("rho_d_init")) rho_d_init = 0.125/5
if (!exists("rho_e_init")) rho_e_init = 8/32
if (!exists("rho_w_init")) rho_w_init = 3/20
if (!exists("rho_b_init")) rho_b_init = 3/20

# feature effect parameters
if (!exists("sigma_d_init")) sigma_d_init = 0.00001
if (!exists("sigma_e_init")) sigma_e_init = 0.00001
if (!exists("sigma_w_init")) sigma_w_init = 0.00001
if (!exists("sigma_b_init")) sigma_b_init = 0.00001
if (!exists("phi_d_init"))     phi_d_init = 0.00001
if (!exists("phi_e_init"))     phi_e_init = 0.00001
if (!exists("phi_w_init"))     phi_w_init = 0.00001
if (!exists("phi_b_init"))     phi_b_init = 0.00001
#
# reversible-jump?
if (!exists("use_rj")) use_rj = false

############################
# Reading epoch age limits #
############################

# reading age ends, old at the top, young at the bottom
#
# e.g.,
# index,age_end
# 4,6.15
# 3,4.135
# 2,2.55
# 1,1.20 
#
# i.e.,
# last entry gives the age at which the youngest epoch ends
# the first entry gives the age at which the fourth epoch ends
# (the oldest epoch runs infinitely into the past, and is not
# specified an end)

times_table = readDataDelimitedFile(times_path, delimiter=",", header=true)
n_epochs = times_table.size() + 1 # times.size()

# 2nd element is the epoch's age end
# old -> young
for (i in 1:(n_epochs-1)) {
    times[i] <- times_table[i][2]
}

####################
# Reading features #
####################

geo_features <- readRegionalFeatures(features_path, delimiter=",", "nan")
geo_features.normalize("within")
geo_features.normalize("between")

# first t is oldest
# last t is youngest
for (t in 1:n_epochs) {
    print("Reading features in time slice " + t)

    feature_CW[t] <- geo_features.get("within", "categorical", t)
    feature_QW[t] <- geo_features.get("within", "quantitative", t)
    feature_CB[t] <- geo_features.get("between", "categorical", t)
    feature_QB[t] <- geo_features.get("between", "quantitative", t)

    for (j in 1:feature_CW[t].size()) {
        layer_CW[t][j] <- feature_CW[t][j].get()
    }

    for (j in 1:feature_QW[t].size()) {
        layer_QW[t][j] <- feature_QW[t][j].get()
    }

    for (j in 1:feature_CB[t].size()) {
        layer_CB[t][j] <- feature_CB[t][j].get()
    }

    for (j in 1:feature_QB[t].size()) {
        layer_QB[t][j] <- feature_QB[t][j].get()
    }
}

# layer objects:
# 1D: time slice; shallowest comma
# 2D: feature; one level deeper comma
# 3D: from-atomic region (rows); two level deeper comma
# 4D: to-atomic region (cols); innermost comma

###################################
# Setting up FIG model parameters #
###################################

# base rate parameters
rho_d ~ dnGamma(0.125,5)
rho_e ~ dnGamma(8,32)
rho_w ~ dnGamma(3,20)
rho_b ~ dnGamma(3,20)

# initializing values (only relevant for inference later)
rho_d.setValue(rho_d_init)
rho_e.setValue(rho_e_init)
rho_w.setValue(rho_w_init)
rho_b.setValue(rho_b_init)

# feature effect parameters
rj_base_sigma_w  = dnNormal(0,1) # prior of "on-value" for RJMCMC
rj_base_sigma_e  = dnNormal(0,1)
rj_base_sigma_d  = dnNormal(0,1)
rj_base_sigma_b  = dnNormal(0,1)
rj_base_phi_w    = dnNormal(0,1)
rj_base_phi_e    = dnNormal(0,1)
rj_base_phi_d    = dnNormal(0,1)
rj_base_phi_b    = dnNormal(0,1)
rj_sigma_w       = dnRJMixture(0.0, rj_base_sigma_w, p=0.5)
rj_sigma_e       = dnRJMixture(0.0, rj_base_sigma_e, p=0.5)
rj_sigma_d       = dnRJMixture(0.0, rj_base_sigma_d, p=0.5)
rj_sigma_b       = dnRJMixture(0.0, rj_base_sigma_b, p=0.5)
rj_phi_w         = dnRJMixture(0.0, rj_base_phi_w, p=0.5)
rj_phi_e         = dnRJMixture(0.0, rj_base_phi_e, p=0.5)
rj_phi_d         = dnRJMixture(0.0, rj_base_phi_d, p=0.5)
rj_phi_b         = dnRJMixture(0.0, rj_base_phi_b, p=0.5)

if (use_rj) {
    for (i in 1:feature_CW[1].size()) sigma_w[i] ~ rj_sigma_w
    for (i in 1:feature_CW[1].size()) sigma_e[i] ~ rj_sigma_e
    for (i in 1:feature_CB[1].size()) sigma_d[i] ~ rj_sigma_d
    for (i in 1:feature_CB[1].size()) sigma_b[i] ~ rj_sigma_b
    for (i in 1:feature_QW[1].size()) phi_w[i] ~ rj_phi_w
    for (i in 1:feature_QW[1].size()) phi_e[i] ~ rj_phi_e
    for (i in 1:feature_QB[1].size()) phi_d[i] ~ rj_phi_d
    for (i in 1:feature_QB[1].size()) phi_b[i] ~ rj_phi_b
} else {
    for (i in 1:feature_CW[1].size()) sigma_w[i] ~ rj_base_sigma_w
    for (i in 1:feature_CW[1].size()) sigma_e[i] ~ rj_base_sigma_e
    for (i in 1:feature_CB[1].size()) sigma_d[i] ~ rj_base_sigma_d
    for (i in 1:feature_CB[1].size()) sigma_b[i] ~ rj_base_sigma_b
    for (i in 1:feature_QW[1].size()) phi_w[i] ~ rj_base_phi_w
    for (i in 1:feature_QW[1].size()) phi_e[i] ~ rj_base_phi_e
    for (i in 1:feature_QB[1].size()) phi_d[i] ~ rj_base_phi_d
    for (i in 1:feature_QB[1].size()) phi_b[i] ~ rj_base_phi_b
}

# initializing values (only relevant for inference later)
# categorical feature effects
for (i in 1:feature_CW[1].size()) sigma_w[i].setValue(sigma_w_init)
for (i in 1:feature_CW[1].size()) sigma_e[i].setValue(sigma_e_init)
for (i in 1:feature_CB[1].size()) sigma_d[i].setValue(sigma_d_init)
for (i in 1:feature_CB[1].size()) sigma_b[i].setValue(sigma_b_init)

# quantitative feature effects
for (i in 1:feature_QW[1].size()) phi_w[i].setValue(phi_w_init)
for (i in 1:feature_QW[1].size()) phi_e[i].setValue(phi_e_init)
for (i in 1:feature_QB[1].size()) phi_d[i].setValue(phi_d_init)
for (i in 1:feature_QB[1].size()) phi_b[i].setValue(phi_b_init)

# hard coding more reasonable priors for phi_d[1] and phi_b[1] in simulations
if (use_rj) {
    phi_d[1] ~ dnRJMixture(0.0, dnUniform(-4,0), p=0.5)
    phi_b[1] ~ dnRJMixture(0.0, dnHalfNormal(offset=0,sd=1), p=0.5)
} else {
    phi_d[1] ~ dnUniform(-3,0)
    phi_b[1] ~ dnHalfNormal(offset=0,sd=1)
}
phi_d[1].setValue(-0.00001)
phi_b[1].setValue(0.00001)

# base-rate multipliers
# first t is oldest
# last t is youngest
for (t in 1:n_epochs) {
    m_w[t] := fnFeatureInformedRates(layer_CW[t], layer_QW[t], sigma_w, phi_w)
    m_e[t] := fnFeatureInformedRates(layer_CW[t], layer_QW[t], sigma_e, phi_e)
    m_d[t] := fnFeatureInformedRates(layer_CB[t], layer_QB[t], sigma_d, phi_d)
    m_b[t] := fnFeatureInformedRates(layer_CB[t], layer_QB[t], sigma_b, phi_b)
}

# quantities we need for later
n_regions = m_b[1].size()
max_range_size = n_regions
n_ranges = 0 # number of states
for (i in 1:max_range_size) n_ranges += choose(n_regions, i)
max_subrange_split_size = n_regions

####################################
# Converting FIG model into GeoSSE #
####################################

# summarize base rates
speciation_rates := [ rho_w, rho_b ]
total_speciation := rho_w + rho_b

# getting dispersal manifested rates
for (t in 1:n_epochs) {
    for (i in 1:n_regions) {
        for (j in 1:m_d[t][i].size()) {
            r_d[t][i][j] := rho_d * m_d[t][i][j]
        }

        for (j in 1:m_e[t][1].size()) {
            r_e[t][j] := rho_e * m_e[t][1][j]
        }
    }

    Q[t] := fnBiogeographyRateMatrix(dispersalRates=r_d[t],
                                     extirpationRates=r_e[t],
                                     maxRangeSize=max_range_size)
}

# get speciation manifested rates
for (t in 1:n_epochs) {
    clado_map[t] := fnBiogeographyCladoEventsBD(speciation_rates=speciation_rates,
                                                within_region_features=m_w[t][1],
                                                between_region_features=m_b[t],
                                                max_range_size=max_range_size,
                                                max_subrange_split_size=max_subrange_split_size)

    lambda[t] := clado_map[t].getSpeciationRateSumPerState()

    omega[t] := clado_map[t].getCladogeneticProbabilityMatrix()

    # monitor variables for absolute speciation rates
    r_w[t] := rho_w * m_w[t][1]
    r_b[t] := rho_b * matrix(m_b[t]) # not for all widespread ranges, just for species with 2-region ranges
}

# get extinction manifested rates
for (t in 1:n_epochs) {
    for (i in 1:n_ranges) {
        mu[t][i] <- abs(0)

        if (i <= n_regions) {
            mu[t][i] := r_e[t][i]
        }
    }
}

# other SSE parameters
# eq. freq at start of process
pi <- simplex(rep(1, n_ranges))

condition = "survival"

rho <- 1.0 # sampling probability

###########################################
# Making simulator (PhyloJunction) string #
###########################################

sigma_true_values_path = model_truth_dir + "sigma_true_vals.tsv"
phi_true_values_path = model_truth_dir + "phi_true_vals.tsv"
rho_true_values_path = model_truth_dir + "rho_true_vals.tsv"
colonization_true_values_path = model_truth_dir + "colonization_true_vals.tsv"

sigma_true_vals_s = "sample\tfeature\tsigma_d\tsigma_e\tsigma_w\tsigma_b\n"
phi_true_vals_s = "sample\tfeature\tphi_d\tphi_e\tphi_w\tphi_b\n"
rho_true_vals_s = "sample\trho_d\trho_e\trho_w\trho_b\n"
colonization_true_vals_s = "sample\ttree_age\tcolonization_age\tsubroot_range\n"

# simulation config
n_samples = 100

for (s_idx in 1:n_samples) {

    # setting a unique seed for each simulation (makes replication possible)
    seed(s_idx)

    valid = false
    while (!valid) {

        print("\nPreparing .pj script string for sample " + s_idx)
        pj_script_idx_path = pj_scripts_dir + "sim" + s_idx + ".pj"

        feat_specific_sigma_true_vals_s = "sample\tsigma_d\tsigma_e\tsigma_w\tsigma_b\n"
        for (c_feat_idx in 1:sigma_d.size()) {
            sigma_d[c_feat_idx].redraw()
            sigma_e[c_feat_idx].redraw()
            sigma_w[c_feat_idx].redraw()
            sigma_b[c_feat_idx].redraw()
            sigma_true_vals_s += s_idx + "\t" + c_feat_idx + "\t" + sigma_d[c_feat_idx] + "\t" + sigma_e[c_feat_idx] + "\t" + sigma_w[c_feat_idx] + "\t" + sigma_b[c_feat_idx] + "\n"

            feat_specific_sigma_true_values_path = model_truth_dir + "sigma_true_vals_sample" + s_idx + "_feat" + c_feat_idx + ".tsv"
            feat_specific_sigma_true_vals_s += s_idx + "\t" + sigma_d[c_feat_idx] + "\t" + sigma_e[c_feat_idx] + "\t" + sigma_w[c_feat_idx] + "\t" + sigma_b[c_feat_idx] + "\n"

            # print("Writing true feature effect values for categorical feature " + c_feat_idx + " in " + feat_specific_sigma_true_values_path)
            write(feat_specific_sigma_true_vals_s, file=feat_specific_sigma_true_values_path)
        }

        feat_specific_phi_true_vals_s = "sample\tphi_d\tphi_e\tphi_w\tphi_b\n"
        for (q_feat_idx in 1:phi_d.size()) {
            phi_d[q_feat_idx].redraw()
            phi_e[q_feat_idx].redraw()
            phi_w[q_feat_idx].redraw()
            phi_b[q_feat_idx].redraw()
            phi_true_vals_s += s_idx + "\t" + q_feat_idx + "\t" + phi_d[q_feat_idx] + "\t" + phi_e[q_feat_idx] + "\t" + phi_w[q_feat_idx] + "\t" + phi_b[q_feat_idx] + "\n"

            feat_specific_phi_true_values_path = model_truth_dir + "phi_true_vals_sample" + s_idx + "_feat" + q_feat_idx + ".tsv"
            feat_specific_phi_true_vals_s += s_idx + "\t" + phi_d[q_feat_idx] + "\t" + phi_e[q_feat_idx] + "\t" + phi_w[q_feat_idx] + "\t" + phi_b[q_feat_idx] + "\n"
        
            # print("Writing true feature effect values for quantitative feature " + q_feat_idx + " in " + feat_specific_phi_true_values_path)
            write(feat_specific_phi_true_vals_s, file=feat_specific_phi_true_values_path)
        }

        rho_d.redraw()
        rho_e.redraw()
        rho_w.redraw()
        rho_b.redraw()
        
        rho_true_vals_s += s_idx + "\t" + rho_d + "\t" + rho_e + "\t" + rho_w + "\t" + rho_b + "\n"

        sample_rho_true_values_path = model_truth_dir + "rho_true_vals_sample" + s_idx + ".tsv"
        sample_rho_true_vals_s = "sample\trho_d\trho_e\trho_w\trho_b\n" + s_idx + "\t" + rho_d + "\t" + rho_e + "\t" + rho_w + "\t" + rho_b + "\n"

        # print("Writing true base rate values for sample " + s_idx + " in " + sample_rho_true_values_path)
        write(sample_rho_true_vals_s, file=sample_rho_true_values_path)

        # origin (seed) age
        or_age = -1.0

        # R, K, O, M, H, Z
        non_continent_region_idxs = [1, 2, 3, 4, 5]

        # 16, 100001, R+Z
        # 17, 010001, K+Z
        # 18, 001001, O+Z
        # 19, 000101, M+Z
        # 20, 000011, H+Z
        translation_table = [16, 17, 18, 19, 20]
        island_names = ["Northwestern islands", "Kauai", "Oahu", "Maui-Nui complex", "Hawaii"]

        max_attempts = 1000
        while (!valid) {
            # cap rejection sampling
            max_attempts -= 1
            # use as many successes we got so far
            if (max_attempts == 0) {
                print("Having trouble colonizing!")
                break
            }

            # decreasing ages
            # times: breakpoints
            
            # draw root age for the whole tree
            # this is the age of the MRCA that separates
            # the ingroup (stem) and the outgroup
            whole_tree_age ~ dnUnif(0,30)
            whole_tree_age.redraw()

            # old -> young
            for (t in 1:n_epochs) {
                
                # adding all dispersal rates from continent into any non-continent region
                d2island_total_rate = 0.0
                for (i in non_continent_region_idxs) {
                    d2island_total_rate += r_d[t][6][i]
                }

                t_d ~ dnExp(d2island_total_rate)

                # if we're in the oldest epoch
                if (t == 1) {
                    island_ori_age = whole_tree_age - t_d
                } else {
                    island_ori_age = min(v(times[t-1], whole_tree_age)) - t_d
                }
                
                if (island_ori_age < 0) {
                    # island_ori_age cannot be negative, done!
                    break
                }

                # overan time interval while still in the second youngest epoch at most
                if (t < n_epochs && (island_ori_age < times[t])) {
                    next
                } else {
                    # event happened within interval t
                    islands_relative_rates = rep(0.0, non_continent_region_idxs.size())

                    for (i in non_continent_region_idxs) {
                        islands_relative_rates[i] = r_d[t][6][i] / d2island_total_rate
                    }

                    # starting region (island), between 1 and 5
                    island_subroot_idx ~ dnCat(simplex(islands_relative_rates))
                    island_subroot_idx.redraw()

                    # note that we have to add the island to the continent
                    # and find that widespread range integer ID
                    subroot_range = translation_table[island_subroot_idx]
                    colonized_island_name = island_names[island_subroot_idx]
                    
                    valid = true
                    break
                }
            }
        }

        if (valid) {
            print("\nWhole tree root age = " + whole_tree_age)
            print("Origin age of island radiation = " + island_ori_age)
            print("Island that got colonized = " + colonized_island_name)

            colonization_true_vals_s += s_idx + "\t" + whole_tree_age + "\t" + island_ori_age + "\t" + subroot_range + "\n"
            sample_colonization_true_values_path = model_truth_dir + "colonization_true_vals_sample" + s_idx + ".tsv"
            sample_colonization_true_vals_s = "sample\ttree_age\tcolonization_age\tsubroot_range\n" + s_idx + "\t" + whole_tree_age + "\t" + island_ori_age + "\t" + subroot_range + "\n"
            # print("Writing true colonization times for sample " + s_idx + " in " + sample_colonization_true_values_path)
            write(sample_colonization_true_vals_s, file=sample_colonization_true_values_path)
        }
    }

    s = "# deterministic nodes\n"
    write(s, file=pj_script_idx_path)

    var_names = [""]
    vidx = 1

    for (t in 1:n_epochs) {
        print("    Doing time slice " + t)

        processed_anc_states_bw_speciation = [-1]
        anc_state_idx = 1

        s += "\n# time slice " + t + "\n"
        # write to existing PJ script file here

        print("      Doing extinction rates")

        for (i in 1:n_regions) {
	    if (r_e[t][i] > 0.0) {
                ii = i - 1
                var_names[vidx] = "det_death_rate" + ii + "_t" + t
                s = var_names[vidx] + " := sse_rate(" + "name=\"mu_" + ii + "_t" + t + "\", " + "value=" + r_e[t][i] + ", " + "states=[" + ii + "], " + "event=\"extinction\", epoch=" + t + ")\n"
                write(s, append=TRUE, file=pj_script_idx_path)

                vidx = vidx + 1
	    }
        }

        print("      Doing transition rates")

        for (i in 1:n_ranges) {
            ii = i - 1
            rate_open = "det_trans_rate" + ii + "_"
            rate_middle = " := sse_rate(" + "name=\"q_" + ii + "_"
            i_state = ", states=[" + ii + ","
            rate_close = "], event=\"transition\", epoch=" + t + ")\n"
        
            for (j in 1:n_ranges) {
                q_tij = Q[t][i][j]
                jj = j - 1

                if (ii != jj) {
		    if (q_tij > 0.0) {
                        var_names[vidx] = rate_open + jj + "_t" + t
                        # var_names[vidx] = "det_trans_rate" + ii  + "_" + jj + "_t" + t
                        # s = var_names[vidx] + " := sse_rate(" + "name=\"q_"+ ii + "_" + jj + "_t" + t + "\", " + "value=" + q_tij + ", states=[" + ii + "," + jj + "], " + "event=\"transition\", epoch=" + t + ")\n"
		        s = var_names[vidx] + rate_middle + jj + "_t" + t + "\", " + "value=" + q_tij + i_state + jj + rate_close

                        write(s, append=TRUE, file=pj_script_idx_path)
                    
                        vidx = vidx + 1
		    }
                }
            }
        }

        # print(s + "\n")

        clado_map_tmp <- clado_map[t]
        clado_map_events_tmp <- clado_map_tmp.getEvents()

        print("      Doing birth rates")

        for (i in 1:clado_map_events_tmp.size()) {
	    idx = clado_map_events_tmp[i]

            if (clado_map_tmp.getRate(idx[1], idx[2], idx[3]) > 0.0) {
                ii = idx[1]
                jj = idx[2]
                kk = idx[3]
                sp_label = "w_speciation"

                if (ii != jj && ii != kk) {
                    sp_label = "bw_speciation"
                }

                if ((ii == jj && ii != kk) || (ii != jj && ii == kk)) {
                    sp_label = "asym_speciation"
                }

                if (sp_label == "bw_speciation" || sp_label=="asym_speciation") {
                # if ((sp_label == "bw_speciation" && (!processed_anc_states_bw_speciation.contains(ii))) || (sp_label=="asym_speciation" && jj >= kk)) {
                    processed_anc_states_bw_speciation[anc_state_idx] = ii
                    anc_state_idx = anc_state_idx + 1
                    var_names[vidx] = "det_birth_rate" + ii + "_" + jj + "_" + kk + "_t" + t

                    s = var_names[vidx] + " := sse_rate(" + "name=\"lambda_" + ii + "_" + jj + "_" + kk + "_t" + t + "\", " + "value=" + clado_map_tmp.getRate(idx[1], idx[2], idx[3]) + ", " + "states=["+ ii + "," + jj + "," + kk + "], " + "event=\"" + sp_label + "\", epoch=" + t + ")\n"
                
                    write(s, append=TRUE, file=pj_script_idx_path)

                    vidx = vidx + 1
		}
            }

            if (sp_label == "w_speciation" && (ii == jj) && (ii == kk)) {
	        if (clado_map_tmp.getRate(idx[1], idx[2], idx[3]) > 0.0) {
                    var_names[vidx] = "det_birth_rate" + ii + "_t" + t
                
                    s = var_names[vidx] + " := sse_rate(" + "name=\"lambda_" + ii + "_" + jj + "_" + kk + "_t" + t + "\", " + "value=" + clado_map_tmp.getRate(idx[1], idx[2], idx[3]) + ", " + "states=["+ ii + "," + ii + "," + ii + "], " + "event=\"" + sp_label + "\", epoch=" + t + ")\n"

                    write(s, append=TRUE, file=pj_script_idx_path)
                
                    vidx = vidx + 1
		}
            }
        }
    }

    # print("      Doing sse_stash()")

    s = "\n# macroevolutionary event handler\nstash := sse_stash(flat_rate_mat="
    
    write(s, append=TRUE, file=pj_script_idx_path)
    
    write(var_names, separator=", ", append=TRUE, file=pj_script_idx_path)
    
    s = ", n_states=" + n_ranges + ", n_epochs=" + n_epochs + ", seed_age=" + island_ori_age + ", epoch_age_ends="
    
    write(s, append=TRUE, file=pj_script_idx_path)

    write(times, separator=", ", append=TRUE, file=pj_script_idx_path)

    s = ")\n\n# tree is distributed as discrete sse\ntrs ~ discrete_sse(n=1" + ", stash=stash, start_state=[" + subroot_range + "], stop=\"age\", stop_value=" + island_ori_age + ", cond_surv=\"true\", cond_obs_both_sides=\"false\", origin=\"false\", min_rec_taxa=15, max_rec_taxa=200, abort_at_obs=5000)"

    write(s, append=TRUE, file=pj_script_idx_path)
}

# if doing more than one sample with this script
#
write(sigma_true_vals_s, file=sigma_true_values_path)
write(phi_true_vals_s, file=phi_true_values_path)
write(rho_true_vals_s, file=rho_true_values_path)
write(colonization_true_vals_s, file=colonization_true_values_path)

q()