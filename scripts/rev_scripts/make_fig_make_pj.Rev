# Script: make_fig_make_pj_exp1.Rev
# Author: Fabio K. Mendes (f.mendes@wustl.edu)
# Date: Aug, 2023

# This script will:
# (1) Read in all features and epoch information,
# (2) Build the FIG model,
# (3) Build a string specifying a PhyloJunction script
#
# NOTE: Run this script from hawaiian_simulations/

#################
# Initial setup #
#################

# seed(12345)

# /Users/binho/Documents/academic_repos/tensorphylo/build/installer/lib/"
tensorphylo_lib_dir = "/Users/binho/Documents/academic_repos/tensorphylo/build/installer/lib/"
loadPlugin("TensorPhylo", tensorphylo_lib_dir)

# setting up paths
if (!exists("experiment_path")) exp_path = "experiment1/"
if (!exists("features_path"))   features_path = exp_path + "feature_summary.csv"
if (!exists("times_path"))      times_path = exp_path + "age_summary.csv"
if (!exists("pj_scripts_dir"))  pj_scripts_dir = exp_path + "pj_scripts/"
if (!exists("model_truth_dir"))  model_truth_dir = exp_path + "model_truth/"

# setting up FIG model quantities we may need to tweak
#
# base rate parameters
if (!exists("rho_d_init")) rho_d_init = 0.001
if (!exists("rho_e_init")) rho_e_init = 0.001
if (!exists("rho_w_init")) rho_w_init = 0.002
if (!exists("rho_b_init")) rho_b_init = 0.002

# feature effect parameters
if (!exists("sigma_d_init")) sigma_d_init = 0.00001
if (!exists("sigma_e_init")) sigma_e_init = 0.00001
if (!exists("sigma_w_init")) sigma_w_init = 0.00001
if (!exists("sigma_b_init")) sigma_b_init = 0.00001
if (!exists("phi_d_init"))     phi_d_init = 0.00001
if (!exists("phi_e_init"))     phi_e_init = 0.00001
if (!exists("phi_w_init"))     phi_w_init = 0.00001
if (!exists("phi_b_init"))     phi_b_init = 0.00001
#
# reversible-jump?
if (!exists("use_rj")) use_rj = false

# simulation config
if (!exists("n_samples"))    n_samples    = 110
if (!exists("max_attempts")) max_attempts = 1000

############################
# Reading epoch age limits #
############################

# reading age ends, old at the top, young at the bottom
#
# e.g.,
# index,age_end
# 4,6.15
# 3,4.135
# 2,2.55
# 1,1.20 
#
# i.e.,
# last entry gives the age at which the youngest epoch ends
# the first entry gives the age at which the fourth epoch ends
# (the oldest epoch runs infinitely into the past, and is not
# specified an end)

times_table = readDataDelimitedFile(times_path, delimiter=",", header=true)
n_epochs = times_table.size() + 1 # times.size()

# 2nd element is the epoch's age end
# old -> young
for (i in 1:(n_epochs-1)) {
    times[i] <- times_table[i][2]
}


####################
# Reading features #
####################

geo_features <- readRegionalFeatures(features_path, delimiter=",", "nan")
geo_features.normalize("within")
geo_features.normalize("between")

# first t is oldest
# last t is youngest
for (t in 1:n_epochs) {
    print("Reading features in time slice " + t)

    feature_CW[t] <- geo_features.get("within", "categorical", t)
    feature_QW[t] <- geo_features.get("within", "quantitative", t)
    feature_CB[t] <- geo_features.get("between", "categorical", t)
    feature_QB[t] <- geo_features.get("between", "quantitative", t)

    for (j in 1:feature_CW[t].size()) {
        layer_CW[t][j] <- feature_CW[t][j].get()
    }

    for (j in 1:feature_QW[t].size()) {
        layer_QW[t][j] <- feature_QW[t][j].get()
    }

    for (j in 1:feature_CB[t].size()) {
        layer_CB[t][j] <- feature_CB[t][j].get()
    }

    for (j in 1:feature_QB[t].size()) {
        layer_QB[t][j] <- feature_QB[t][j].get()
    }
}

# layer objects:
# 1D: time slice; shallowest comma
# 2D: feature; one level deeper comma
# 3D: from-atomic region (rows); two level deeper comma
# 4D: to-atomic region (cols); innermost comma


###################################
# Setting up FIG model parameters #
###################################

# base rate parameters
rho_d ~ dnExp(1)
rho_e ~ dnExp(1)
rho_w ~ dnExp(1)
rho_b ~ dnExp(1)

# initializing values (only relevant for inference later)
rho_d.setValue(rho_d_init)
rho_e.setValue(rho_e_init)
rho_w.setValue(rho_w_init)
rho_b.setValue(rho_b_init)

# feature effect parameters
rj_base_sigma_w  = dnNormal(0,1) # prior of "on-value" for RJMCMC
rj_base_sigma_e  = dnNormal(0,1)
rj_base_sigma_d  = dnNormal(0,1)
rj_base_sigma_b  = dnNormal(0,1)
rj_base_phi_w    = dnNormal(0,1)
rj_base_phi_e    = dnNormal(0,1)
rj_base_phi_d    = dnNormal(0,1)
rj_base_phi_b    = dnNormal(0,1)
rj_sigma_w       = dnRJMixture(0.0, rj_base_sigma_w, p=0.5)
rj_sigma_e       = dnRJMixture(0.0, rj_base_sigma_e, p=0.5)
rj_sigma_d       = dnRJMixture(0.0, rj_base_sigma_d, p=0.5)
rj_sigma_b       = dnRJMixture(0.0, rj_base_sigma_b, p=0.5)
rj_phi_w         = dnRJMixture(0.0, rj_base_phi_w, p=0.5)
rj_phi_e         = dnRJMixture(0.0, rj_base_phi_e, p=0.5)
rj_phi_d         = dnRJMixture(0.0, rj_base_phi_d, p=0.5)
rj_phi_b         = dnRJMixture(0.0, rj_base_phi_b, p=0.5)

if (use_rj) {
    for (i in 1:feature_CW[1].size()) sigma_w[i] ~ rj_sigma_w
    for (i in 1:feature_CW[1].size()) sigma_e[i] ~ rj_sigma_e
    for (i in 1:feature_CB[1].size()) sigma_d[i] ~ rj_sigma_d
    for (i in 1:feature_CB[1].size()) sigma_b[i] ~ rj_sigma_b
    for (i in 1:feature_QW[1].size()) phi_w[i] ~ rj_phi_w
    for (i in 1:feature_QW[1].size()) phi_e[i] ~ rj_phi_e
    for (i in 1:feature_QB[1].size()) phi_d[i] ~ rj_phi_d
    for (i in 1:feature_QB[1].size()) phi_b[i] ~ rj_phi_b
} else {
    for (i in 1:feature_CW[1].size()) sigma_w[i] ~ rj_base_sigma_w
    for (i in 1:feature_CW[1].size()) sigma_e[i] ~ rj_base_sigma_e
    for (i in 1:feature_CB[1].size()) sigma_d[i] ~ rj_base_sigma_d
    for (i in 1:feature_CB[1].size()) sigma_b[i] ~ rj_base_sigma_b
    for (i in 1:feature_QW[1].size()) phi_w[i] ~ rj_base_phi_w
    for (i in 1:feature_QW[1].size()) phi_e[i] ~ rj_base_phi_e
    for (i in 1:feature_QB[1].size()) phi_d[i] ~ rj_base_phi_d
    for (i in 1:feature_QB[1].size()) phi_b[i] ~ rj_base_phi_b
}

# initializing values (only relevant for inference later)
# categorical feature effects
for (i in 1:feature_CW[1].size()) sigma_w[i].setValue(sigma_w_init)
for (i in 1:feature_CW[1].size()) sigma_e[i].setValue(sigma_e_init)
for (i in 1:feature_CB[1].size()) sigma_d[i].setValue(sigma_d_init)
for (i in 1:feature_CB[1].size()) sigma_b[i].setValue(sigma_b_init)

# quantitative feature effects
for (i in 1:feature_QW[1].size()) phi_w[i].setValue(phi_w_init)
for (i in 1:feature_QW[1].size()) phi_e[i].setValue(phi_e_init)
for (i in 1:feature_QB[1].size()) phi_d[i].setValue(phi_d_init)
for (i in 1:feature_QB[1].size()) phi_b[i].setValue(phi_b_init)

# base-rate multipliers
# first t is oldest
# last t is youngest
for (t in 1:n_epochs) {
    m_w[t] := fnFeatureInformedRates(layer_CW[t], layer_QW[t], sigma_w, phi_w)
    m_e[t] := fnFeatureInformedRates(layer_CW[t], layer_QW[t], sigma_e, phi_e)
    m_d[t] := fnFeatureInformedRates(layer_CB[t], layer_QB[t], sigma_d, phi_d)
    m_b[t] := fnFeatureInformedRates(layer_CB[t], layer_QB[t], sigma_b, phi_b)
}

# quantities we need for later
n_regions = m_b[1].size()
max_range_size = n_regions
n_ranges = 0 # number of states
for (i in 1:max_range_size) n_ranges += choose(n_regions, i)
max_subrange_split_size = n_regions


####################################
# Converting FIG model into GeoSSE #
####################################

# summarize base rates
speciation_rates := [ rho_w, rho_b ]
total_speciation := rho_w + rho_b

# getting dispersal manifested rates
for (t in 1:n_epochs) {
    for (i in 1:n_regions) {
        for (j in 1:m_d[t][i].size()) {
            r_d[t][i][j] := rho_d * m_d[t][i][j]
        }

        for (j in 1:m_e[t][1].size()) {
            r_e[t][j] := rho_e * m_e[t][1][j]
        }
    }

    Q[t] := fnBiogeographyRateMatrix(dispersalRates=r_d[t],
                                     extirpationRates=r_e[t],
                                     maxRangeSize=max_range_size)
}

# get speciation manifested rates
for (t in 1:n_epochs) {
    clado_map[t] := fnBiogeographyCladoEventsBD(speciation_rates=speciation_rates,
                                                within_region_features=m_w[t][1],
                                                between_region_features=m_b[t],
                                                max_range_size=max_range_size,
                                                max_subrange_split_size=max_subrange_split_size)

    lambda[t] := clado_map[t].getSpeciationRateSumPerState()

    omega[t] := clado_map[t].getCladogeneticProbabilityMatrix()

    # monitor variables for absolute speciation rates
    r_w[t] := rho_w * m_w[t][1]
    r_b[t] := rho_b * matrix(m_b[t]) # not for all widespread ranges, just for species with 2-region ranges
}

# get extinction manifested rates
for (t in 1:n_epochs) {
    for (i in 1:n_ranges) {
        mu[t][i] <- abs(0)

        if (i <= n_regions) {
            mu[t][i] := r_e[t][i]
        }
    }
}

# other SSE parameters
# eq. freq at start of process
pi <- simplex(rep(1, n_ranges))

condition = "survival"

rho <- 1.0 # sampling probability


##################################################
# Draw time and range for an island colonization #
# to match Hawaiian data                         #
##################################################

# origin (seed) age
or_age = -1.0

# R, K, O, M, H, Z
non_continent_region_idxs = [1, 2, 3, 4, 5]

# 16, 100001, R+Z
# 17, 010001, K+Z
# 18, 001001, O+Z
# 19, 000101, M+Z
# 20, 000011, H+Z
translation_table = [16, 17, 18, 19, 20]
island_names = ["Northwestern islands", "Kauai", "Oahu", "Maui-Nui complex", "Hawaii"]

valid = false
while (!valid) {
    # cap rejection sampling
    max_attempts -= 1
    # use as many successes we got so far
    if (max_attempts <= 0) {
	q()
    }

    # decreasing ages
    # times: breakpoints
    
    # draw root age for the whole tree
    # this is the age of the MRCA that separates
    # the ingroup (stem) and the outgroup
    whole_tree_age ~ dnUnif(0,30)

    # old -> young
    for (t in 1:n_epochs) {
        
        # adding all dispersal rates from continent into any non-continent region
        d2island_total_rate = 0.0
        for (i in non_continent_region_idxs) {
            d2island_total_rate += r_d[t][6][i]
        }

        t_d ~ dnExp(d2island_total_rate)

        # if we're in the oldest epoch
        if (t == 1) {
            island_or_age = whole_tree_age - t_d
        } else {
            island_or_age = times[t-1] - t_d
        }
        
        if (island_or_age < 0) {
            # island_or_age cannot be negative, done!
            break
        }

        # overan time interval while still in the second youngest epoch at most
        if (t < n_epochs && (island_or_age < times[t])) {
            next
        } else {
            # event happened within interval t
            islands_relative_rates = rep(0.0, non_continent_region_idxs.size())

            for (i in non_continent_region_idxs) {
                islands_relative_rates[i] = r_d[t][6][i] / d2island_total_rate
            }


            # starting region (island), between 1 and 5
            island_subroot_idx ~ dnCat(simplex(islands_relative_rates))

            # note that we have to add the island to the continent
            # and find that widespread range integer ID
            subroot_range = translation_table[island_subroot_idx]
            colonized_island_name = island_names[island_subroot_idx]
            
            valid = true
            break
        }
    }
}

print("Whole tree root age = " + whole_tree_age)
print("Origin age of island radiation = " + island_or_age)
print("Island that got colonized = " + colonized_island_name)

xxxx

###########################################
# Making simulator (PhyloJunction) string #
###########################################

sigma_true_values_path = model_truth_dir + "sigma_true_vals.tsv"
phi_true_values_path = model_truth_dir + "phi_true_vals.tsv"
rho_true_values_path = model_truth_dir + "rho_true_vals.tsv"

sigma_true_vals_s = "sample\tfeature\tsigma_d\tsigma_e\tsigma_w\tsigma_b\n"
phi_true_vals_s = "sample\tfeature\tphi_d\tphi_e\tphi_w\tphi_b\n"
rho_init_vals_s = "sample\trho_d\trho_e\trho_w\trho_b\n"

for (s_idx in 1:n_samples) {

    print("Preparing .pj script string for sample " + s_idx)

    feat_specific_sigma_true_vals_s = "sample\tsigma_d\tsigma_e\tsigma_w\tsigma_b\n"
    for (c_feat_idx in 1:sigma_d.size()) {
        sigma_d[c_feat_idx].redraw()
        sigma_e[c_feat_idx].redraw()
        sigma_w[c_feat_idx].redraw()
        sigma_b[c_feat_idx].redraw()
        sigma_true_vals_s += s_idx + "\t" + c_feat_idx + "\t" + sigma_d[c_feat_idx] + "\t" + sigma_e[c_feat_idx] + "\t" + sigma_w[c_feat_idx] + "\t" + sigma_b[c_feat_idx] + "\n"

        feat_specific_sigma_true_values_path = model_truth_dir + "sigma_true_vals_sample" + s_idx + "_feat" + c_feat_idx + ".tsv"
        feat_specific_sigma_true_vals_s += s_idx + "\t" + sigma_d[c_feat_idx] + "\t" + sigma_e[c_feat_idx] + "\t" + sigma_w[c_feat_idx] + "\t" + sigma_b[c_feat_idx] + "\n"

        print("Writing true feature effect values for categorical feature " + c_feat_idx + " in " + feat_specific_sigma_true_values_path)

        write(feat_specific_sigma_true_vals_s, file=feat_specific_sigma_true_values_path)
    }

    feat_specific_phi_true_vals_s = "sample\tphi_d\tphi_e\tphi_w\tphi_b\n"
    for (q_feat_idx in 1:phi_d.size()) {
        phi_d[q_feat_idx].redraw()
        phi_e[q_feat_idx].redraw()
        phi_w[q_feat_idx].redraw()
        phi_b[q_feat_idx].redraw()
        phi_true_vals_s += s_idx + "\t" + c_feat_idx + "\t" + phi_d[c_feat_idx] + "\t" + phi_e[c_feat_idx] + "\t" + phi_w[c_feat_idx] + "\t" + phi_b[c_feat_idx] + "\n"

        feat_specific_phi_true_values_path = model_truth_dir + "phi_true_vals_sample" + s_idx + "_feat" + c_feat_idx + ".tsv"
        feat_specific_phi_true_vals_s += s_idx + "\t" + phi_d[c_feat_idx] + "\t" + phi_e[c_feat_idx] + "\t" + phi_w[c_feat_idx] + "\t" + phi_b[c_feat_idx] + "\n"
       
        print("Writing true feature effect values for quantitative feature " + q_feat_idx + " in " + feat_specific_phi_true_values_path)
        
        write(feat_specific_phi_true_vals_s, file=feat_specific_phi_init_values_path)
    }
}

# adding stuff here

}

write(sigma_true_vals_s, file=sigma_true_values_path)
write(phi_true_vals_s, file=phi_true_values_path)
write(rho_true_vals_s, file=rho_true_values_path)

# Here:
# Wait until PhyloJunction finishes simulations
# Then run MCMC on simulated data