# Script: make_fig_make_pj_exp1.Rev
# Author: Fabio K. Mendes (f.mendes@wustl.edu)
# Date: Aug, 2023

# This script will:
# (1) Read in all features and epoch information,
# (2) Build the FIG model,
# (3) Build a string specifying a PhyloJunction script
#
# NOTE: Run this script from hawaiian_simulations/

#################
# Initial setup #
#################

seed(12345)

# /Users/binho/Documents/academic_repos/tensorphylo/build/installer/lib/"
tensorphylo_lib_dir = "put_the_path_to_tensorphylo's_lib_here/"
loadPlugin("TensorPhylo", tensorphylo_lib_dir)

# setting up paths
if (!exists("experiment_path")) exp_path = "experiment1/"
if (!exists("features_path"))   features_path = exp_path + "feature_summary.csv"
if (!exists("times_path"))      times_path = "age_summary.csv"
if (!exists("pj_scripts_dir"))  pj_scripts_dir = exp_path + "pj_scripts/"
if (!exists("model_truth_dir"))  model_truth_dir = exp_path + "model_truth/"

# setting up FIG model quantities we may need to tweak
#
# base rate parameters
if (!exists(rho_d_init)) rho_d_init = 0.0001
if (!exists(rho_e_init)) rho_e_init = 0.0001
if (!exists(rho_w_init)) rho_w_init = 0.0002
if (!exists(rho_b_init)) rho_b_init = 0.0002
#
# feature effect parameters
if (!exists(sigma_d_init)) sigma_d_init = 0.00001
if (!exists(sigma_e_init)) sigma_e_init = 0.00001
if (!exists(sigma_w_init)) sigma_w_init = 0.00001
if (!exists(sigma_b_init)) sigma_b_init = 0.00001
if (!exists(phi_d_init))     phi_d_init = 0.00001
if (!exists(phi_e_init))     phi_e_init = 0.00001
if (!exists(phi_w_init))     phi_w_init = 0.00001
if (!exists(phi_b_init))     phi_b_init = 0.00001
#
# reversible-jump?
if (!exists("use_rj")) use_rj = false

# simulation config
if (!exists("n_samples")) n_samples = 110


############################
# Reading epoch age limits #
############################

# reading age ends, old at the top, young at the bottom
#
# e.g.,
# index,age_end
# 4,6.15
# 3,4.135
# 2,2.55
# 1,1.20 
#
# i.e.,
# last entry gives the age at which the youngest epoch ends
# the first entry gives the age at which the fourth epoch ends
# (the oldest epoch runs infinitely into the past, and is not
# specified an end)

times_table = readDataDelimitedFile(times_path, delimiter=",", header=true)
n_epochs = times_table.size() + 1 # times.size()

# 2nd element is the epoch's age end
# old -> young
for (i in 1:(n_epochs-1)) {
    times[i] <- times_table[i][2]
}



####################
# Reading features #
####################

geo_features <- readRegionalFeatures(features_path, delimiter=",")
geo_features.normalize("within")
geo_features.normalize("between")

# first t is oldest
# last t is youngest
for (t in 1:n_epochs) {
    print("Reading features in time slice " + t)

    feature_CW[t] <- geo_features.get("within", "categorical", t)
    feature_QW[t] <- geo_features.get("within", "quantitative", t)
    feature_CB[t] <- geo_features.get("between", "categorical", t)
    feature_QB[t] <- geo_features.get("between", "quantitative", t)

    for (j in 1:feature_CW[t].size()) {
        layer_CW[t][j] <- feature_CW[t][j].get()
    }

    for (j in 1:feature_QW[t].size()) {
        layer_QW[t][j] <- feature_QW[t][j].get()
    }

    for (j in 1:feature_CB[t].size()) {
        layer_CB[t][j] <- feature_CB[t][j].get()
    }

    for (j in 1:feature_QB[t].size()) {
        layer_QB[t][j] <- feature_QB[t][j].get()
    }
}

# layer objects:
# 1D: time slice; shallowest comma
# 2D: feature; one level deeper comma
# 3D: from-atomic region (rows); two level deeper comma
# 4D: to-atomic region (cols); innermost comma


###################################
# Setting up FIG model parameters #
###################################

# base rate parameters
rho_d ~ dnExp(1)
rho_e ~ dnExp(1)
rho_w ~ dnExp(1)
rho_b ~ dnExp(1)

# initializing values (only relevant for inference later)
# rho_d.setValue(rho_d_init)
# rho_e.setValue(rho_e_init)
# rho_w.setValue(rho_w_init)
# rho_b.setValue(rho_b_init)

# feature effect parameters
rj_base_sigma_w  = dnNormal(0,1) # prior of "on-value" for RJMCMC
rj_base_sigma_e  = dnNormal(0,1)
rj_base_sigma_d  = dnNormal(0,1)
rj_base_sigma_b  = dnNormal(0,1)
rj_base_phi_w    = dnNormal(0,1)
rj_base_phi_e    = dnNormal(0,1)
rj_base_phi_d    = dnNormal(0,1)
rj_base_phi_b    = dnNormal(0,1)
rj_sigma_w       = dnRJMixture(0.0, rj_base_sigma_w, p=0.5)
rj_sigma_e       = dnRJMixture(0.0, rj_base_sigma_e, p=0.5)
rj_sigma_d       = dnRJMixture(0.0, rj_base_sigma_d, p=0.5)
rj_sigma_b       = dnRJMixture(0.0, rj_base_sigma_b, p=0.5)
rj_phi_w         = dnRJMixture(0.0, rj_base_phi_w, p=0.5)
rj_phi_e         = dnRJMixture(0.0, rj_base_phi_e, p=0.5)
rj_phi_d         = dnRJMixture(0.0, rj_base_phi_d, p=0.5)
rj_phi_b         = dnRJMixture(0.0, rj_base_phi_b, p=0.5)

if (use_rj) {
    for (i in 1:feature_CW[1].size()) sigma_w[i] ~ rj_sigma_w
    for (i in 1:feature_CW[1].size()) sigma_e[i] ~ rj_sigma_e
    for (i in 1:feature_CB[1].size()) sigma_d[i] ~ rj_sigma_d
    for (i in 1:feature_CB[1].size()) sigma_b[i] ~ rj_sigma_b
    for (i in 1:feature_QW[1].size()) phi_w[i] ~ rj_phi_w
    for (i in 1:feature_QW[1].size()) phi_e[i] ~ rj_phi_e
    for (i in 1:feature_QB[1].size()) phi_d[i] ~ rj_phi_d
    for (i in 1:feature_QB[1].size()) phi_b[i] ~ rj_phi_b
} else {
    for (i in 1:feature_CW[1].size()) sigma_w[i] ~ rj_base_sigma_w
    for (i in 1:feature_CW[1].size()) sigma_e[i] ~ rj_base_sigma_e
    for (i in 1:feature_CB[1].size()) sigma_d[i] ~ rj_base_sigma_d
    for (i in 1:feature_CB[1].size()) sigma_b[i] ~ rj_base_sigma_b
    for (i in 1:feature_QW[1].size()) phi_w[i] ~ rj_base_phi_w
    for (i in 1:feature_QW[1].size()) phi_e[i] ~ rj_base_phi_e
    for (i in 1:feature_QB[1].size()) phi_d[i] ~ rj_base_phi_d
    for (i in 1:feature_QB[1].size()) phi_b[i] ~ rj_base_phi_b
}

# initializing values (only relevant for inference later)
# categorical feature effects
# for (i in 1:feature_CW[1].size()) sigma_w[i].setValue(sigma_w_init)
# for (i in 1:feature_CW[1].size()) sigma_e[i].setValue(sigma_e_init)
# for (i in 1:feature_CB[1].size()) sigma_d[i].setValue(sigma_d_init)
# for (i in 1:feature_CB[1].size()) sigma_b[i].setValue(sigma_b_init)

# quantitative feature effects
# for (i in 1:feature_QW[1].size()) phi_w[i].setValue(phi_w_init)
# for (i in 1:feature_QW[1].size()) phi_e[i].setValue(phi_e_init)
# for (i in 1:feature_QB[1].size()) phi_d[i].setValue(phi_d_init)
# for (i in 1:feature_QB[1].size()) phi_b[i].setValue(phi_b_init)

# base-rate multipliers
# first t is oldest
# last t is youngest
for (t in 1:n_epochs) {
    m_w[t] := fnFeatureInformedRates(layer_CW[t], layer_QW[t], sigma_w, phi_w)
    m_e[t] := fnFeatureInformedRates(layer_CW[t], layer_QW[t], sigma_e, phi_e)
    m_d[t] := fnFeatureInformedRates(layer_CB[t], layer_QB[t], sigma_d, phi_d)
    m_b[t] := fnFeatureInformedRates(layer_CB[t], layer_QB[t], sigma_b, phi_b)
}

# quantities we need for later
n_regions = m_b[1].size()
max_range_size = n_regions
n_ranges = 0 # number of states
for (i in 1:max_range_size) n_ranges += choose(n_regions, i)
max_subrange_split_size = n_regions


####################################
# Converting FIG model into GeoSSE #
####################################

# summarize base rates
speciation_rates := [ rho_w, rho_b ]
total_speciation := rho_w + rho_b

# getting dispersal manifested rates
for (t in 1:n_epochs) {
    for (i in 1:n_regions) {
        for (j in 1:m_d[k][i].size()) {
            r_d[t][i][j] := rho_d * m_d[t][i][j]
        }

        for (j in 1:m_e[t][1].size()) {
            r_e[t][j] := rho_e * m_e[t][1][j]
        }
    }

    Q[t] := fnBiogeographyRateMatrix(dispersalRates=r_d[t],
                                     extirpationRates=r_e[t],
                                     maxRangeSize=max_range_size)
}

# get speciation manifested rates
for (t in 1:n_epochs) {
    clado_map[t] := fnBiogeographyCladoEventsBD(speciation_rates=speciation_rates,
                                                within_region_features=m_w[t][1],
                                                between_region_features=m_b[t],
                                                max_range_size=max_range_size,
                                                max_subrange_split_size=max_subrange_split_size)

    lambda[t] := clado_map[t].getSpeciationRateSumPerState()

    omega[t] := clado_map[t].getCladogeneticProbabilityMatrix()

    # monitor variables for absolute speciation rates
    r_w[t] := rho_w * m_w[t][1]
    r_b[t] := rho_b * matrix(m_b[t]) # not for all widespread ranges, just for species with 2-region ranges
}

# get extinction manifested rates
for (t in 1:n_epochs) {
    for (i in 1:n_states) {
        mu[t][i] <- abs(0)

        if (i <= n_regions) {
            mu[t][i] := r_e[t][i]
        }
    }
}

# other SSE parameters
# eq. freq at start of process
pi <- simplex(rep(1, n_ranges))

condition = "survival"

rho <- 1.0 # sampling probability


##################################################
# Draw time and range for an island colonization #
# to match Hawaiian data                         #
##################################################

# origin (seed) age
or_age = -1.0

# R, K, O, M, H, Z
non_continent_region_idxs = [1, 2, 3, 4, 5]

valid = false
while (!valid) {
    # decreasing ages
    # times: breakpoints
    
    for (t in 1:n_epochs) {
        
        # adding all dispersal rates from continent into any non-continent region
        d2island_total_rate = 0.0
        for (i in non_continent_region_idxs) {
            d2island_total_rate += r_d[t][5][i]
        }

        t_d ~ dnExp(d2island_total_rate)
        or_age = (times[t] - t_d) # origin age

        # overan time interval
        if (or_age < times[t+1]) {
            continue; # do nothing
        }

        # event happened within interval t
        else {

            islands_relative_rates = rep(0.0, non_continent_region_idxs.size())
            for (i in non_continent_region_idxs) {
                islands_relative_rates[i] = r_d[t][5][i] / d2island_total_rate
            }

            # starting region (island)
            island_subroot ~ dnCat(islands_relative_rates)

            # note that we have to add the island to the continent
            # and find that widespread range integer ID
            subroot_range = find_state_number(Z, island_subroot) # PSEUDOCODE STILL
            
            valid = true
            break
        }
    }
} # we have O, X and S


###########################################
# Making simulator (PhyloJunction) string #
###########################################

sigma_true_values_path = model_truth_dir + "sigma_true_vals.tsv"
phi_true_values_path = model_truth_dir + "phi_true_vals.tsv"
rho_true_values_path = model_truth_dir + "rho_true_vals.tsv"

sigma_true_vals_s = "sample\tfeature\tsigma_d\tsigma_e\tsigma_w\tsigma_b\n"
phi_true_vals_s = "sample\tfeature\tphi_d\tphi_e\tphi_w\tphi_b\n"
rho_init_vals_s = "sample\trho_d\trho_e\trho_w\trho_b\n"

for (s_idx in 1:n_samples) {

    print("Preparing .pj script string for sample " + s_idx)

    feat_specific_sigma_true_vals_s = "sample\tsigma_d\tsigma_e\tsigma_w\tsigma_b\n"
    for (c_feat_idx in 1:sigma_d.size()) {
        sigma_d[c_feat_idx].redraw()
        sigma_e[c_feat_idx].redraw()
        sigma_w[c_feat_idx].redraw()
        sigma_b[c_feat_idx].redraw()
        sigma_true_vals_s += s_idx + "\t" + c_feat_idx + "\t" + sigma_d[c_feat_idx] + "\t" + sigma_e[c_feat_idx] + "\t" + sigma_w[c_feat_idx] + "\t" + sigma_b[c_feat_idx] + "\n"

        feat_specific_sigma_true_values_path = model_truth_dir + "sigma_true_vals_sample" + s_idx + "_feat" + c_feat_idx + ".tsv"
        feat_specific_sigma_true_vals_s += s_idx + "\t" + sigma_d[c_feat_idx] + "\t" + sigma_e[c_feat_idx] + "\t" + sigma_w[c_feat_idx] + "\t" + sigma_b[c_feat_idx] + "\n"

        print("Writing true feature effect values for categorical feature " + c_feat_idx + " in " + feat_specific_sigma_true_values_path)

        write(feat_specific_sigma_true_vals_s, file=feat_specific_sigma_true_values_path)
    }

    feat_specific_phi_true_vals_s = "sample\tphi_d\tphi_e\tphi_w\tphi_b\n"
    for (q_feat_idx in 1:phi_d.size()) {
        phi_d[q_feat_idx].redraw()
        phi_e[q_feat_idx].redraw()
        phi_w[q_feat_idx].redraw()
        phi_b[q_feat_idx].redraw()
        phi_true_vals_s += s_idx + "\t" + c_feat_idx + "\t" + phi_d[c_feat_idx] + "\t" + phi_e[c_feat_idx] + "\t" + phi_w[c_feat_idx] + "\t" + phi_b[c_feat_idx] + "\n"

        feat_specific_phi_true_values_path = model_truth_dir + "phi_true_vals_sample" + s_idx + "_feat" + c_feat_idx + ".tsv"
        feat_specific_phi_true_vals_s += s_idx + "\t" + phi_d[c_feat_idx] + "\t" + phi_e[c_feat_idx] + "\t" + phi_w[c_feat_idx] + "\t" + phi_b[c_feat_idx] + "\n"
       
        print("Writing true feature effect values for quantitative feature " + q_feat_idx + " in " + feat_specific_phi_true_values_path)
        
        write(feat_specific_phi_true_vals_s, file=feat_specific_phi_init_values_path)
    }
}

# adding stuff here

}

write(sigma_true_vals_s, file=sigma_true_values_path)
write(phi_true_vals_s, file=phi_true_values_path)
write(rho_true_vals_s, file=rho_true_values_path)