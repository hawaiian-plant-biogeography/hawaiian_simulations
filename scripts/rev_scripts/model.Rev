# Script: model.Rev
# Authors: Fabio K. Mendes (f.mendes@wustl.edu) & Sarah K. Swiston (sarah.k.swiston@wustl.edu)
# Date: January 15, 2024

# This script will:
# (1) Read in all features and epoch information
# (2) Build the FIG model
#
# NOTE: Run this script from hawaiian_simulations/

#################
# Initial setup #
#################

#loadPlugin("TensorPhylo", "/Users/binho/.local/lib/")
#loadPlugin("TensorPhylo", "/tensorphylo/build/installer/lib")
loadPlugin("TensorPhylo", "/Users/mlandis/.local/lib/tensorphylo")

# sim number
if (!exists("s_idx")) s_idx = 18 #9999

# settings
if (!exists("use_rj")) use_rj = false
if (!exists("analysis_type")) analysis_type = v("sim","inf")[1]

# setting up paths
if (!exists("exp_path")) exp_path                 = "experiment1/"
if (!exists("geo_path")) geo_path                 = v("realistic_paleogeo/","present_only_geo/")[1]
if (!exists("features_path")) features_path       = exp_path + geo_path + "feature_summary.csv"
if (!exists("times_path")) times_path             = exp_path + geo_path + "age_summary.csv"
if (!exists("pj_scripts_dir")) pj_scripts_dir     = exp_path + "pj_scripts/"
if (!exists("pj_scripts_py_dir")) pj_scripts_py_dir     = exp_path + "pj_scripts_generated_in_py/"
if (!exists("model_truth_dir")) model_truth_dir   = exp_path + "model_truth/"
if (!exists("geosse_rates_dir")) geosse_rates_dir = exp_path + "geosse_rates_for_pj_scripts/"

# setting up FIG model quantities we may need to tweak
#
# base rate parameters
if (!exists("rho_d_init")) rho_d_init = 0.125/5
if (!exists("rho_e_init")) rho_e_init = 1/10
if (!exists("rho_w_init")) rho_w_init = 1/20
if (!exists("rho_b_init")) rho_b_init = 3*5/20

# feature effect parameters
if (!exists("sigma_d_init")) sigma_d_init = 0.00001
if (!exists("sigma_e_init")) sigma_e_init = 0.00001
if (!exists("sigma_w_init")) sigma_w_init = 0.00001
if (!exists("sigma_b_init")) sigma_b_init = 0.00001
if (!exists("phi_d_init"))     phi_d_init = 0.00001
if (!exists("phi_e_init"))     phi_e_init = 0.00001
if (!exists("phi_w_init"))     phi_w_init = 0.00001
if (!exists("phi_b_init"))     phi_b_init = 0.00001

############################
# Reading epoch age limits #
############################

# reading age ends, young at the top, old at the bottom
#
# e.g.,
# index,age_end
# 1,1.10
# 2,2.10
# 3,3.93
# 4,6.00
# 5,7.75
# 6,17.75 
#
# i.e.,
# last entry gives the age at which the youngest epoch ends
# the first entry gives the age at which the oldest epoch ends
# (the oldest epoch runs infinitely into the past, and is not
# specified a start)

times_table = readDataDelimitedFile(times_path, delimiter=",", header=true)
n_epochs = times_table.size() + 1


# 4th element is the epoch's age end
# young -> old (forward in time, NOT how PhyloJunction likes it)
for (i in 1:(n_epochs-1)) {
    times_fwd[i] <- times_table[i][4]
}

# old -> young
for (i in 1:(n_epochs-1)) {
    times[i] <- times_fwd[n_epochs-i]
}

####################
# Reading features #
####################

geo_features <- readRegionalFeatures(features_path, delimiter=",", "nan")
geo_features.normalize("within")
geo_features.normalize("between")

# first t is oldest
# last t is youngest
# SKS 2024/01/15 I rearranged the realistic_paleogeo dataset to reflect this
# May have to update other analyses?
for (t in 1:n_epochs) {
    print("Reading features in time slice " + t)

    feature_CW[t] <- geo_features.get("within", "categorical", t)
    feature_QW[t] <- geo_features.get("within", "quantitative", t)
    feature_CB[t] <- geo_features.get("between", "categorical", t)
    feature_QB[t] <- geo_features.get("between", "quantitative", t)

    for (j in 1:feature_CW[t].size()) {
        layer_CW[t][j] <- feature_CW[t][j].get()
    }

    for (j in 1:feature_QW[t].size()) {
        layer_QW[t][j] <- feature_QW[t][j].get()
    }

    for (j in 1:feature_CB[t].size()) {
        layer_CB[t][j] <- feature_CB[t][j].get()
    }

    for (j in 1:feature_QB[t].size()) {
        layer_QB[t][j] <- feature_QB[t][j].get()
    }
}

# layer objects:
# 1D: time slice; shallowest comma
# 2D: feature; one level deeper comma
# 3D: from-atomic region (rows); two level deeper comma
# 4D: to-atomic region (cols); innermost comma

###################################
# Setting up FIG model parameters #
###################################

# base rate parameters
rho_d ~ dnGamma(1,20)
rho_e ~ dnGamma(1,20)
rho_w ~ dnGamma(1,20)
rho_b ~ dnGamma(10,20)

# initializing values (only relevant for inference later)
rho_d.setValue(rho_d_init)
rho_e.setValue(rho_e_init)
rho_w.setValue(rho_w_init)
rho_b.setValue(rho_b_init)

# feature effect parameters
if (analysis_type == "inf") {
    rj_base_sigma_w  = dnNormal(0,1) # prior of "on-value" for RJMCMC
    rj_base_sigma_e  = dnNormal(0,1)
    rj_base_sigma_d  = dnNormal(0,1)
    rj_base_sigma_b  = dnNormal(0,1)
    rj_base_phi_w    = dnNormal(0,1)
    rj_base_phi_e    = dnNormal(0,1)
    rj_base_phi_d    = dnNormal(0,1)
    rj_base_phi_b    = dnNormal(0,1)
}
if (analysis_type == "sim") {
    rj_base_sigma_w  = dnUniform(-2,2) # prior of "on-value" for RJMCMC
    rj_base_sigma_e  = dnUniform(-2,2)
    rj_base_sigma_d  = dnUniform(-2,2)
    rj_base_sigma_b  = dnUniform(-2,2)
    rj_base_phi_w    = dnUniform(-2,2)
    rj_base_phi_e    = dnUniform(-2,2)
    rj_base_phi_d    = dnUniform(-2,2)
    rj_base_phi_b    = dnUniform(-2,2)
}
rj_sigma_w       = dnRJMixture(0.0, rj_base_sigma_w, p=0.5)
rj_sigma_e       = dnRJMixture(0.0, rj_base_sigma_e, p=0.5)
rj_sigma_d       = dnRJMixture(0.0, rj_base_sigma_d, p=0.5)
rj_sigma_b       = dnRJMixture(0.0, rj_base_sigma_b, p=0.5)
rj_phi_w         = dnRJMixture(0.0, rj_base_phi_w, p=0.5)
rj_phi_e         = dnRJMixture(0.0, rj_base_phi_e, p=0.5)
rj_phi_d         = dnRJMixture(0.0, rj_base_phi_d, p=0.5)
rj_phi_b         = dnRJMixture(0.0, rj_base_phi_b, p=0.5)

if (use_rj) {
    for (i in 1:feature_CW[1].size()) sigma_w[i] ~ rj_sigma_w
    for (i in 1:feature_CW[1].size()) sigma_e[i] ~ rj_sigma_e
    for (i in 1:feature_CB[1].size()) sigma_d[i] ~ rj_sigma_d
    for (i in 1:feature_CB[1].size()) sigma_b[i] ~ rj_sigma_b
    for (i in 1:feature_QW[1].size()) phi_w[i] ~ rj_phi_w
    for (i in 1:feature_QW[1].size()) phi_e[i] ~ rj_phi_e
    for (i in 1:feature_QB[1].size()) phi_d[i] ~ rj_phi_d
    for (i in 1:feature_QB[1].size()) phi_b[i] ~ rj_phi_b
} else {
    for (i in 1:feature_CW[1].size()) sigma_w[i] ~ rj_base_sigma_w
    for (i in 1:feature_CW[1].size()) sigma_e[i] ~ rj_base_sigma_e
    for (i in 1:feature_CB[1].size()) sigma_d[i] ~ rj_base_sigma_d
    for (i in 1:feature_CB[1].size()) sigma_b[i] ~ rj_base_sigma_b
    for (i in 1:feature_QW[1].size()) phi_w[i] ~ rj_base_phi_w
    for (i in 1:feature_QW[1].size()) phi_e[i] ~ rj_base_phi_e
    for (i in 1:feature_QB[1].size()) phi_d[i] ~ rj_base_phi_d
    for (i in 1:feature_QB[1].size()) phi_b[i] ~ rj_base_phi_b
}

# initializing values (only relevant for inference later)
# categorical feature effects
for (i in 1:feature_CW[1].size()) sigma_w[i].setValue(sigma_w_init)
for (i in 1:feature_CW[1].size()) sigma_e[i].setValue(sigma_e_init)
for (i in 1:feature_CB[1].size()) sigma_d[i].setValue(sigma_d_init)
for (i in 1:feature_CB[1].size()) sigma_b[i].setValue(sigma_b_init)

# quantitative feature effects
for (i in 1:feature_QW[1].size()) phi_w[i].setValue(phi_w_init)
for (i in 1:feature_QW[1].size()) phi_e[i].setValue(phi_e_init)
for (i in 1:feature_QB[1].size()) phi_d[i].setValue(phi_d_init)
for (i in 1:feature_QB[1].size()) phi_b[i].setValue(phi_b_init)

# hard coding more reasonable priors for phi_d[1] and phi_b[1] in simulations
if (analysis_type == "sim") {
    if (use_rj) {
        phi_d[1] ~ dnRJMixture(0.0, dnUniform(-4,0), p=0.5)   # distance (km)
        phi_b[1] ~ dnRJMixture(0.0, dnUniform(0,4), p=0.5)    # distance (km)
        sigma_w[1] ~ dnRJMixture(0.0, dnUniform(0,4), p=0.5)  # is high island? (0=no, 1=yes)
        sigma_e[1] ~ dnRJMixture(0.0, dnUniform(-4,0), p=0.5) # is high island? (0=no, 1=yes)
    } else {
        phi_d[1] ~ dnUniform(-4,0)   # distance (km)
        phi_b[1] ~ dnUniform(0,4)    # distance (km)
        sigma_w[1] ~ dnUniform(0,4)  # is high island? (0=no, 1=yes)
        sigma_e[1] ~ dnUniform(-4,0) # is high island? (0=no, 1=yes)
    }
}

# base-rate multipliers
# first t is oldest
# last t is youngest
for (t in 1:n_epochs) {
    m_w[t] := fnFeatureInformedRates(layer_CW[t], layer_QW[t], sigma_w, phi_w, null_rate=0)
    m_e[t] := fnFeatureInformedRates(layer_CW[t], layer_QW[t], sigma_e, phi_e, null_rate=1e3)
    m_d[t] := fnFeatureInformedRates(layer_CB[t], layer_QB[t], sigma_d, phi_d, null_rate=0)
    m_b[t] := fnFeatureInformedRates(layer_CB[t], layer_QB[t], sigma_b, phi_b, null_rate=1)
}


# quantities we need for later
n_regions = m_b[1].size()
max_range_size = n_regions
n_ranges = 0 # number of states
for (i in 1:max_range_size) n_ranges += choose(n_regions, i)
max_subrange_split_size = n_regions

####################################
# Converting FIG model into GeoSSE #
####################################

# summarize base rates
speciation_rates := [ rho_w, rho_b ]
total_speciation := rho_w + rho_b

# getting dispersal manifested rates
for (t in 1:n_epochs) {
    for (i in 1:n_regions) {
        for (j in 1:m_d[t][i].size()) {
            r_d[t][i][j] := rho_d * m_d[t][i][j]
        }

        for (j in 1:m_e[t][1].size()) {
            r_e[t][j] := rho_e * m_e[t][1][j]
        }
    }

    Q[t] := fnBiogeographyRateMatrix(dispersalRates=r_d[t],
                                     extirpationRates=r_e[t],
                                     maxRangeSize=max_range_size)
}

# Q[1].getStateDescriptions()

# get speciation manifested rates
for (t in 1:n_epochs) {
    clado_map[t] := fnBiogeographyCladoEventsBD(speciation_rates=speciation_rates,
                                                within_region_features=m_w[t][1],
                                                between_region_features=m_b[t],
                                                max_range_size=max_range_size,
                                                max_subrange_split_size=max_subrange_split_size)

    lambda[t] := clado_map[t].getSpeciationRateSumPerState()

    omega[t] := clado_map[t].getCladogeneticProbabilityMatrix()

    # monitor variables for absolute speciation rates
    r_w[t] := rho_w * m_w[t][1]
    r_b[t] := rho_b * matrix(m_b[t]) # not for all widespread ranges, just for species with 2-region ranges
}

# get extinction manifested rates
for (t in 1:n_epochs) {
    for (i in 1:n_ranges) {
        mu[t][i] <- abs(0)

        if (i <= n_regions) {
            mu[t][i] := r_e[t][i]
        }
    }
}

# ... done running, expects another script to take over ...
