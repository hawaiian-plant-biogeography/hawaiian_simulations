7: Pulling from sswiston/rb_tp
Digest: sha256:d44e872f338de09f70d9d986f16e4daf3ef531cec9699d3183f0e1e60425bd91
Status: Image is up to date for sswiston/rb_tp:7
docker.io/sswiston/rb_tp:7
/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
2024-03-20_15:39:47
RevBayes: generate island radiation rates (1)

RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2392-g9a7fd3) on Mon Mar  4 19:45:37 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "./scripts/rev_scripts/make_fig_rate_output.Rev"
   Processing file "scripts/rev_scripts/model.Rev"
   Error:	The folder doesn't exist.
   Error:	Problem processing line 17 in file "scripts/rev_scripts/model.Rev"
   Error:	Problem processing line 21 in file "./scripts/rev_scripts/make_fig_rate_output.Rev"
> RevBayes: generate Phylojunction scripts (1)
python3 ./scripts/make_pj.py 1 experiment1/geosse_rates_for_pj_scripts/ experiment1/model_truth/ experiment1/pj_scripts_generated_in_py/ 127 7 "17.750, 7.750, 6.000, 3.930, 2.100, 1.100"
Everything OK with provided arguments!
Preparing .pj script for simulation 1.
...done!
Phylojunction: simulate island radiation (1)
Matplotlib created a temporary cache directory at /tmp/275327.tmpdir/matplotlib-6tetxin9 because the default path (/home/michael.landis/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
Reading script ./experiment1/pj_scripts_generated_in_py/sim1.pj
    ... done!
Writing ./experiment1/pj_output/figures/sample1_trs1_1
RevBayes: simulate sequence data and make final tree (1)


RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2392-g9a7fd3) on Mon Mar  4 19:45:37 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "./scripts/rev_scripts/sim_sequences.Rev"
Working on simulation 1
root age 29.3218 colonization age 19.9437 origin time 0.952526 ingroup branch 10.3306
Got root and colonization ages
Grafted outgroup onto tree
Grafted outgroup onto tip data
   Attempting to read the contents of file "sample1.tre"
   Successfully read file
Removed extinct taxa and saved new tree
Simulated sequences
/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
WARNING: ignoring environment value of R_HOME
During startup - Warning messages:
1: Setting LC_CTYPE failed, using "C" 
2: Setting LC_COLLATE failed, using "C" 
3: Setting LC_TIME failed, using "C" 
4: Setting LC_MESSAGES failed, using "C" 
5: Setting LC_MONETARY failed, using "C" 
6: Setting LC_PAPER failed, using "C" 
7: Setting LC_MEASUREMENT failed, using "C" 
Taxon= 1 	range_int= 6 	range_bit= 0000001 	region_set= Z 
Taxon= 2 	range_int= 36 	range_bit= 0101100 	region_set= NOM 
Taxon= 3 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 4 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 5 	range_int= 1 	range_bit= 0100000 	region_set= N 
Taxon= 6 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 7 	range_int= 11 	range_bit= 0101000 	region_set= NO 
Taxon= 8 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 9 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 10 	range_int= 1 	range_bit= 0100000 	region_set= N 
Taxon= 11 	range_int= 0 	range_bit= 1000000 	region_set= G 
Taxon= 12 	range_int= 0 	range_bit= 1000000 	region_set= G 
Taxon= 13 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 14 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 15 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 16 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 17 	range_int= 18 	range_bit= 0100010 	region_set= NH 
Taxon= 18 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 19 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 20 	range_int= 16 	range_bit= 0001100 	region_set= OM 
Taxon= 21 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 22 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 23 	range_int= 12 	range_bit= 0011000 	region_set= KO 
Taxon= 24 	range_int= 12 	range_bit= 0011000 	region_set= KO 
Taxon= 25 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 26 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 27 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 28 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 29 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 30 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 31 	range_int= 0 	range_bit= 1000000 	region_set= G 
Taxon= 32 	range_int= 1 	range_bit= 0100000 	region_set= N 
Taxon= 33 	range_int= 16 	range_bit= 0001100 	region_set= OM 
Taxon= 34 	range_int= 0 	range_bit= 1000000 	region_set= G 
Taxon= 35 	range_int= 0 	range_bit= 1000000 	region_set= G 
Taxon= 36 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 37 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 38 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 39 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 40 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 41 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 42 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 43 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 44 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 45 	range_int= 9 	range_bit= 0110000 	region_set= NK 
Taxon= 46 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 47 	range_int= 9 	range_bit= 0110000 	region_set= NK 
Taxon= 48 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 49 	range_int= 43 	range_bit= 0011010 	region_set= KOH 
Taxon= 50 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 51 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 52 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 53 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 54 	range_int= 8 	range_bit= 1010000 	region_set= GK 
Taxon= 55 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 56 	range_int= 12 	range_bit= 0011000 	region_set= KO 
Taxon= 57 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 58 	range_int= 19 	range_bit= 0010010 	region_set= KH 
Taxon= 59 	range_int= 43 	range_bit= 0011010 	region_set= KOH 
Taxon= 60 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 61 	range_int= 15 	range_bit= 0010100 	region_set= KM 
Taxon= 62 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 63 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 64 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 65 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 66 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 67 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 68 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 69 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 70 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 71 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 72 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 73 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 74 	range_int= 12 	range_bit= 0011000 	region_set= KO 
Taxon= 75 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 76 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 77 	range_int= 1 	range_bit= 0100000 	region_set= N 
Taxon= 78 	range_int= 6 	range_bit= 0000001 	region_set= Z 
Taxon= 79 	range_int= 28 	range_bit= 1110000 	region_set= GNK 
Taxon= 80 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 81 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 82 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 83 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 84 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 85 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 86 	range_int= 16 	range_bit= 0001100 	region_set= OM 
Taxon= 87 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 88 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 89 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 90 	range_int= 14 	range_bit= 0100100 	region_set= NM 
Taxon= 91 	range_int= 6 	range_bit= 0000001 	region_set= Z 
Taxon= 92 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 93 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 94 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 95 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 96 	range_int= 1 	range_bit= 0100000 	region_set= N 
Taxon= 97 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 98 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 99 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 100 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 101 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 102 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 103 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 104 	range_int= 4 	range_bit= 0000100 	region_set= M 
Taxon= 105 	range_int= 19 	range_bit= 0010010 	region_set= KH 
Taxon= 106 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 107 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 108 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 109 	range_int= 11 	range_bit= 0101000 	region_set= NO 
Taxon= 110 	range_int= 6 	range_bit= 0000001 	region_set= Z 
Taxon= 111 	range_int= 6 	range_bit= 0000001 	region_set= Z 
Taxon= 112 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 113 	range_int= 12 	range_bit= 0011000 	region_set= KO 
Taxon= 114 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 115 	range_int= 1 	range_bit= 0100000 	region_set= N 
Taxon= 116 	range_int= 0 	range_bit= 1000000 	region_set= G 
Taxon= 117 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 118 	range_int= 1 	range_bit= 0100000 	region_set= N 
Taxon= 119 	range_int= 19 	range_bit= 0010010 	region_set= KH 
Taxon= 120 	range_int= 9 	range_bit= 0110000 	region_set= NK 
null device 
          1 

------------------------------------------------------------
Sender: LSF System <lsfadmin@compute1-exec-221.ris.wustl.edu>
Subject: Job 275327: <2> in cluster <compute1-lsf> Done

Job <2> was submitted from host <compute1-client-1.ris.wustl.edu> by user <michael.landis> in cluster <compute1-lsf> at Wed Mar 20 10:39:44 2024
Job was executed on host(s) <4*compute1-exec-221.ris.wustl.edu>, in queue <general>, as user <michael.landis> in cluster <compute1-lsf> at Wed Mar 20 10:39:46 2024
</home/michael.landis> was used as the home directory.
</storage1/fs1/michael.landis/Active/hawaiian_simulations/> was used as the working directory.
Started at Wed Mar 20 10:39:46 2024
Terminated at Wed Mar 20 10:40:01 2024
Results reported at Wed Mar 20 10:40:01 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/bin/bash /storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/sim_one.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   10.23 sec.
    Max Memory :                                 9 MB
    Average Memory :                             7.25 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               4087.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                16
    Run time :                                   15 sec.
    Turnaround time :                            17 sec.

The output (if any) is above this job summary.

7: Pulling from sswiston/rb_tp
Digest: sha256:d44e872f338de09f70d9d986f16e4daf3ef531cec9699d3183f0e1e60425bd91
Status: Image is up to date for sswiston/rb_tp:7
docker.io/sswiston/rb_tp:7
/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
2024-03-20_15:40:32
RevBayes: generate island radiation rates (2)

RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2392-g9a7fd3) on Mon Mar  4 19:45:37 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "./scripts/rev_scripts/make_fig_rate_output.Rev"
   Processing file "scripts/rev_scripts/model.Rev"
   Error:	The folder doesn't exist.
   Error:	Problem processing line 17 in file "scripts/rev_scripts/model.Rev"
   Error:	Problem processing line 21 in file "./scripts/rev_scripts/make_fig_rate_output.Rev"
> RevBayes: generate Phylojunction scripts (2)
python3 ./scripts/make_pj.py 2 experiment1/geosse_rates_for_pj_scripts/ experiment1/model_truth/ experiment1/pj_scripts_generated_in_py/ 127 7 "17.750, 7.750, 6.000, 3.930, 2.100, 1.100"
Everything OK with provided arguments!
Preparing .pj script for simulation 2.
...done!
Phylojunction: simulate island radiation (2)
Matplotlib created a temporary cache directory at /tmp/275337.tmpdir/matplotlib-ma3af3tq because the default path (/home/michael.landis/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
Reading script ./experiment1/pj_scripts_generated_in_py/sim2.pj
    ... done!
Writing ./experiment1/pj_output/figures/sample2_trs1_1
RevBayes: simulate sequence data and make final tree (2)


RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2392-g9a7fd3) on Mon Mar  4 19:45:37 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "./scripts/rev_scripts/sim_sequences.Rev"
Working on simulation 2
root age 28.1996 colonization age 3.70164 origin time 0.429263 ingroup branch 24.9272
Got root and colonization ages
Grafted outgroup onto tree
Grafted outgroup onto tip data
   Attempting to read the contents of file "sample2.tre"
   Successfully read file
Removed extinct taxa and saved new tree
Simulated sequences
/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
WARNING: ignoring environment value of R_HOME
During startup - Warning messages:
1: Setting LC_CTYPE failed, using "C" 
2: Setting LC_COLLATE failed, using "C" 
3: Setting LC_TIME failed, using "C" 
4: Setting LC_MESSAGES failed, using "C" 
5: Setting LC_MONETARY failed, using "C" 
6: Setting LC_PAPER failed, using "C" 
7: Setting LC_MEASUREMENT failed, using "C" 
Taxon= 1 	range_int= 6 	range_bit= 0000001 	region_set= Z 
Taxon= 2 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 3 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 4 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 5 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 6 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 7 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 8 	range_int= 8 	range_bit= 1010000 	region_set= GK 
Taxon= 9 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 10 	range_int= 98 	range_bit= 1111100 	region_set= GNKOM 
Taxon= 11 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 12 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 13 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 14 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 15 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 16 	range_int= 3 	range_bit= 0001000 	region_set= O 
null device 
          1 

------------------------------------------------------------
Sender: LSF System <lsfadmin@compute1-exec-285.ris.wustl.edu>
Subject: Job 275337: <2> in cluster <compute1-lsf> Done

Job <2> was submitted from host <compute1-client-1.ris.wustl.edu> by user <michael.landis> in cluster <compute1-lsf> at Wed Mar 20 10:40:27 2024
Job was executed on host(s) <4*compute1-exec-285.ris.wustl.edu>, in queue <general>, as user <michael.landis> in cluster <compute1-lsf> at Wed Mar 20 10:40:31 2024
</home/michael.landis> was used as the home directory.
</storage1/fs1/michael.landis/Active/hawaiian_simulations/> was used as the working directory.
Started at Wed Mar 20 10:40:31 2024
Terminated at Wed Mar 20 10:41:02 2024
Results reported at Wed Mar 20 10:41:02 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/bin/bash /storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/sim_one.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   10.31 sec.
    Max Memory :                                 9 MB
    Average Memory :                             8.00 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               4087.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                20
    Run time :                                   31 sec.
    Turnaround time :                            35 sec.

The output (if any) is above this job summary.

7: Pulling from sswiston/rb_tp
Digest: sha256:d44e872f338de09f70d9d986f16e4daf3ef531cec9699d3183f0e1e60425bd91
Status: Image is up to date for sswiston/rb_tp:7
docker.io/sswiston/rb_tp:7
/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
2024-03-20_15:58:49
RevBayes: generate island radiation rates (2)

RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2392-g9a7fd3) on Mon Mar  4 19:45:37 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "./scripts/rev_scripts/make_fig_rate_output.Rev"
   Processing file "scripts/rev_scripts/model.Rev"
   Error:	The folder doesn't exist.
   Error:	Problem processing line 17 in file "scripts/rev_scripts/model.Rev"
   Error:	Problem processing line 21 in file "./scripts/rev_scripts/make_fig_rate_output.Rev"
> RevBayes: generate Phylojunction scripts (2)
python3 ./scripts/make_pj.py 2 experiment1/geosse_rates_for_pj_scripts/ experiment1/model_truth/ experiment1/pj_scripts_generated_in_py/ 127 7 "17.750, 7.750, 6.000, 3.930, 2.100, 1.100"
Everything OK with provided arguments!
Preparing .pj script for simulation 2.
...done!
Phylojunction: simulate island radiation (2)
Matplotlib created a temporary cache directory at /tmp/275434.tmpdir/matplotlib-yoenirtb because the default path (/home/michael.landis/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
Reading script ./experiment1/pj_scripts_generated_in_py/sim2.pj
    ... done!
Writing ./experiment1/pj_output/figures/sample2_trs1_1
RevBayes: simulate sequence data and make final tree (2)


RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2392-g9a7fd3) on Mon Mar  4 19:45:37 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "./scripts/rev_scripts/sim_sequences.Rev"
Working on simulation 2
root age 28.1996 colonization age 3.70164 origin time 0.429263 ingroup branch 24.9272
Got root and colonization ages
Grafted outgroup onto tree
Grafted outgroup onto tip data
   Attempting to read the contents of file "sample2.tre"
   Successfully read file
Removed extinct taxa and saved new tree
Simulated sequences
/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
WARNING: ignoring environment value of R_HOME
During startup - Warning messages:
1: Setting LC_CTYPE failed, using "C" 
2: Setting LC_COLLATE failed, using "C" 
3: Setting LC_TIME failed, using "C" 
4: Setting LC_MESSAGES failed, using "C" 
5: Setting LC_MONETARY failed, using "C" 
6: Setting LC_PAPER failed, using "C" 
7: Setting LC_MEASUREMENT failed, using "C" 
Taxon= 1 	range_int= 6 	range_bit= 0000001 	region_set= Z 
Taxon= 2 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 3 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 4 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 5 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 6 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 7 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 8 	range_int= 8 	range_bit= 1010000 	region_set= GK 
Taxon= 9 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 10 	range_int= 98 	range_bit= 1111100 	region_set= GNKOM 
Taxon= 11 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 12 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 13 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 14 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 15 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 16 	range_int= 3 	range_bit= 0001000 	region_set= O 
null device 
          1 

------------------------------------------------------------
Sender: LSF System <lsfadmin@compute1-exec-284.ris.wustl.edu>
Subject: Job 275434: <2> in cluster <compute1-lsf> Done

Job <2> was submitted from host <compute1-client-1.ris.wustl.edu> by user <michael.landis> in cluster <compute1-lsf> at Wed Mar 20 10:58:45 2024
Job was executed on host(s) <4*compute1-exec-284.ris.wustl.edu>, in queue <general>, as user <michael.landis> in cluster <compute1-lsf> at Wed Mar 20 10:58:48 2024
</home/michael.landis> was used as the home directory.
</storage1/fs1/michael.landis/Active/hawaiian_simulations/> was used as the working directory.
Started at Wed Mar 20 10:58:48 2024
Terminated at Wed Mar 20 10:59:03 2024
Results reported at Wed Mar 20 10:59:03 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/bin/bash /storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/sim_one.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   10.38 sec.
    Max Memory :                                 9 MB
    Average Memory :                             7.50 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               4087.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                22
    Run time :                                   15 sec.
    Turnaround time :                            18 sec.

The output (if any) is above this job summary.

7: Pulling from sswiston/rb_tp
Digest: sha256:d44e872f338de09f70d9d986f16e4daf3ef531cec9699d3183f0e1e60425bd91
Status: Image is up to date for sswiston/rb_tp:7
docker.io/sswiston/rb_tp:7
/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
2024-04-03_15:32:29
RevBayes: generate island radiation rates (2)

RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2392-g9a7fd3) on Mon Mar  4 19:45:37 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "./scripts/rev_scripts/make_fig_rate_output.Rev"
   Processing file "scripts/rev_scripts/model.Rev"
   Error:	The folder doesn't exist.
   Error:	Problem processing line 17 in file "scripts/rev_scripts/model.Rev"
   Error:	Problem processing line 21 in file "./scripts/rev_scripts/make_fig_rate_output.Rev"
> RevBayes: generate Phylojunction scripts (2)
python3 ./scripts/make_pj.py 2 experiment1/geosse_rates_for_pj_scripts/ experiment1/model_truth/ experiment1/pj_scripts_generated_in_py/ 127 7 "17.750, 7.750, 6.000, 3.930, 2.100, 1.100"
Everything OK with provided arguments!
Preparing .pj script for simulation 2.
...done!
Phylojunction: simulate island radiation (2)
Matplotlib created a temporary cache directory at /tmp/201666.tmpdir/matplotlib-3pcev1cn because the default path (/home/michael.landis/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Traceback (most recent call last):
  File "/.local/bin/pjcli", line 33, in <module>
    sys.exit(load_entry_point('PhyloJunction', 'console_scripts', 'pjcli')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/.local/bin/pjcli", line 25, in importlib_load_entry_point
    return next(matches).load()
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/importlib/metadata/__init__.py", line 202, in load
    module = import_module(match.group('module'))
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1204, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/PhyloJunction/src/phylojunction/interface/pjcli/pj_cli.py", line 6, in <module>
    import phylojunction.interface.cmdbox.cmd_parse as cmd
  File "/PhyloJunction/src/phylojunction/interface/cmdbox/cmd_parse.py", line 14, in <module>
    import phylojunction.interface.grammar.dn_grammar as dngrammar
  File "/PhyloJunction/src/phylojunction/interface/grammar/dn_grammar.py", line 4, in <module>
    import phylojunction.distribution.dn_parametric as dnpar
  File "/PhyloJunction/src/phylojunction/distribution/dn_parametric.py", line 5, in <module>
    from scipy.stats import expon, lognorm, norm, gamma, uniform  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scipy/stats/__init__.py", line 608, in <module>
    from ._stats_py import *
  File "/usr/lib/python3/dist-packages/scipy/stats/_stats_py.py", line 46, in <module>
    from . import distributions
  File "/usr/lib/python3/dist-packages/scipy/stats/distributions.py", line 8, in <module>
    from ._distn_infrastructure import (rv_discrete, rv_continuous, rv_frozen)  # noqa: F401
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scipy/stats/_distn_infrastructure.py", line 23, in <module>
    from scipy import optimize
  File "<frozen importlib._bootstrap>", line 1229, in _handle_fromlist
  File "/usr/lib/python3/dist-packages/scipy/__init__.py", line 189, in __getattr__
    return _importlib.import_module(f'scipy.{name}')
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3/dist-packages/scipy/optimize/__init__.py", line 410, in <module>
    from ._minimize import *
  File "/usr/lib/python3/dist-packages/scipy/optimize/_minimize.py", line 31, in <module>
    from ._tnc import _minimize_tnc
  File "/usr/lib/python3/dist-packages/scipy/optimize/_tnc.py", line 35, in <module>
    from scipy.optimize import _moduleTNC as moduleTNC
  File "<frozen importlib._bootstrap>", line 405, in parent
KeyboardInterrupt

------------------------------------------------------------
Sender: LSF System <lsfadmin@compute1-exec-154.ris.wustl.edu>
Subject: Job 201666: <2> in cluster <compute1-lsf> Exited

Job <2> was submitted from host <compute1-client-1.ris.wustl.edu> by user <michael.landis> in cluster <compute1-lsf> at Wed Apr  3 10:32:22 2024
Job was executed on host(s) <4*compute1-exec-154.ris.wustl.edu>, in queue <general>, as user <michael.landis> in cluster <compute1-lsf> at Wed Apr  3 10:32:27 2024
</home/michael.landis> was used as the home directory.
</storage1/fs1/michael.landis/Active/hawaiian_simulations/> was used as the working directory.
Started at Wed Apr  3 10:32:27 2024
Terminated at Wed Apr  3 10:32:47 2024
Results reported at Wed Apr  3 10:32:47 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/bin/bash /storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/sim_one.sh
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 130.

Resource usage summary:

    CPU time :                                   10.20 sec.
    Max Memory :                                 9 MB
    Average Memory :                             7.50 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               4087.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                15
    Run time :                                   20 sec.
    Turnaround time :                            25 sec.

The output (if any) is above this job summary.

7: Pulling from sswiston/rb_tp
09e2bc8a597c: Pulling fs layer
2b9b886a42b7: Pulling fs layer
8ce14f1b6040: Pulling fs layer
bc3ece41e309: Pulling fs layer
2e1749e41102: Pulling fs layer
ef83c79745fb: Pulling fs layer
7e173d175d10: Pulling fs layer
e763f42586ce: Pulling fs layer
c4087cb4d203: Pulling fs layer
6bb80b25c679: Pulling fs layer
22deef2c6d74: Pulling fs layer
6f174565ecc2: Pulling fs layer
7e173d175d10: Waiting
e763f42586ce: Waiting
d94d92919122: Pulling fs layer
d4d0501e8640: Pulling fs layer
bc3ece41e309: Waiting
4ba75a747dc2: Pulling fs layer
c4087cb4d203: Waiting
bdfba4e06563: Pulling fs layer
6bb80b25c679: Waiting
da15b734f4e0: Pulling fs layer
425eed1469d0: Pulling fs layer
91d9256d1553: Pulling fs layer
22deef2c6d74: Waiting
1cc816f5fb7c: Pulling fs layer
6f174565ecc2: Waiting
bcd418f9087a: Pulling fs layer
7d025bc8d970: Pulling fs layer
4ba75a747dc2: Waiting
d4d0501e8640: Waiting
da15b734f4e0: Waiting
00c5aaadc119: Pulling fs layer
bdfba4e06563: Waiting
d94d92919122: Waiting
2e1749e41102: Waiting
a8eca5b08ab0: Pulling fs layer
425eed1469d0: Waiting
ef83c79745fb: Waiting
91d9256d1553: Waiting
1cc816f5fb7c: Waiting
bcd418f9087a: Waiting
339d14fa1e4c: Pulling fs layer
7d025bc8d970: Waiting
00c5aaadc119: Waiting
a8eca5b08ab0: Waiting
4f4fb700ef54: Pulling fs layer
339d14fa1e4c: Waiting
5eb1a1bfa10e: Pulling fs layer
415592e71761: Pulling fs layer
9f5fbef0620e: Pulling fs layer
a78a1dc0f4ef: Pulling fs layer
5eb1a1bfa10e: Waiting
415592e71761: Waiting
b255d9d428d8: Pulling fs layer
9f5fbef0620e: Waiting
a78a1dc0f4ef: Waiting
b255d9d428d8: Waiting
de70acc16f82: Pulling fs layer
fa1002082786: Pulling fs layer
c3b64c473cfe: Pulling fs layer
5e97fff42a10: Pulling fs layer
81c46080858b: Pulling fs layer
c39bdad10cf5: Pulling fs layer
2b40fb470834: Pulling fs layer
58d9ecc6cfdb: Pulling fs layer
de70acc16f82: Waiting
c39bdad10cf5: Waiting
4105f2da20ce: Pulling fs layer
5e97fff42a10: Waiting
81c46080858b: Waiting
fa1002082786: Waiting
2b40fb470834: Waiting
c3b64c473cfe: Waiting
91d0d0f534d2: Pulling fs layer
58d9ecc6cfdb: Waiting
4105f2da20ce: Waiting
ec78cb8480bd: Pulling fs layer
96109d199f8e: Pulling fs layer
def4274856d4: Pulling fs layer
0dbac9a3d1e0: Pulling fs layer
86cfc42b53c3: Pulling fs layer
4faf7f61c2dd: Pulling fs layer
91d0d0f534d2: Waiting
0dbac9a3d1e0: Waiting
ec78cb8480bd: Waiting
96109d199f8e: Waiting
def4274856d4: Waiting
24bca1ad81f4: Pulling fs layer
4faf7f61c2dd: Waiting
704da0235df3: Pulling fs layer
24bca1ad81f4: Waiting
86cfc42b53c3: Waiting
7d6447c960f3: Pulling fs layer
3b0b69eb049b: Pulling fs layer
537dec467165: Pulling fs layer
51b20db66ae9: Pulling fs layer
ff3bbbedf6ac: Pulling fs layer
704da0235df3: Waiting
dc7747ed74a7: Pulling fs layer
51b20db66ae9: Waiting
537dec467165: Waiting
7d6447c960f3: Waiting
3b0b69eb049b: Waiting
271ae3ecbe0d: Pulling fs layer
ff3bbbedf6ac: Waiting
dc7747ed74a7: Waiting
9b987fd087da: Pulling fs layer
fb9e55e586fa: Pulling fs layer
23510a6343fd: Pulling fs layer
fd4bbda75e78: Pulling fs layer
9b987fd087da: Waiting
23510a6343fd: Waiting
f03725552f0a: Pulling fs layer
271ae3ecbe0d: Waiting
fd4bbda75e78: Waiting
fb9e55e586fa: Waiting
37ee2f377bce: Pulling fs layer
bb63d693d815: Pulling fs layer
fd172d8c5862: Pulling fs layer
460c6c77ab97: Pulling fs layer
4e71aa62ff60: Pulling fs layer
fd172d8c5862: Waiting
c9f866f195f3: Pulling fs layer
bb63d693d815: Waiting
f03725552f0a: Waiting
37ee2f377bce: Waiting
32341e95c9ae: Pulling fs layer
c9f866f195f3: Waiting
079fdcbfbf54: Pulling fs layer
8728d7d7d7db: Pulling fs layer
d7cc881e1ebb: Pulling fs layer
42809a0f6939: Pulling fs layer
14f6d686ad0e: Pulling fs layer
32341e95c9ae: Waiting
8728d7d7d7db: Waiting
d7cc881e1ebb: Waiting
079fdcbfbf54: Waiting
7983115a1993: Pulling fs layer
42809a0f6939: Waiting
0f51bfe3804f: Pulling fs layer
14f6d686ad0e: Waiting
7983115a1993: Waiting
9d81585664ac: Pulling fs layer
342d991a1373: Pulling fs layer
9dcae794478d: Pulling fs layer
e047a7a0ca04: Pulling fs layer
6d3a284f9141: Pulling fs layer
e047a7a0ca04: Waiting
5ea6df8e7a07: Pulling fs layer
0f51bfe3804f: Waiting
c7c6489014d8: Pulling fs layer
342d991a1373: Waiting
5ea6df8e7a07: Waiting
8bc5ad50c954: Pulling fs layer
5264701fb427: Pulling fs layer
fef2e7cb801c: Pulling fs layer
6cadd8d78d75: Pulling fs layer
5264701fb427: Waiting
c7c6489014d8: Waiting
8bc5ad50c954: Waiting
fef2e7cb801c: Waiting
59106d4298b7: Pulling fs layer
59cb04e44bd9: Pulling fs layer
dcf44bd1bad8: Pulling fs layer
2d8af8ec16b4: Pulling fs layer
6cadd8d78d75: Waiting
bda034caa3f7: Pulling fs layer
dcf44bd1bad8: Waiting
59cb04e44bd9: Waiting
59106d4298b7: Waiting
bf061592f1b5: Pulling fs layer
2d8af8ec16b4: Waiting
bda034caa3f7: Waiting
b0f2b7224b35: Pulling fs layer
ae2f82e34288: Pulling fs layer
bf061592f1b5: Waiting
10064aa6ffbc: Pulling fs layer
b0f2b7224b35: Waiting
ae2f82e34288: Waiting
f27a436e1e5f: Pulling fs layer
80d88015f8e8: Pulling fs layer
f27a436e1e5f: Waiting
7e7114afa1df: Pulling fs layer
80d88015f8e8: Waiting
d196687fcc5a: Pulling fs layer
7e7114afa1df: Waiting
bae910fe3da9: Pulling fs layer
e974a9812dac: Pulling fs layer
bae910fe3da9: Waiting
6102c2ad01e7: Pulling fs layer
45036c5db557: Pulling fs layer
e974a9812dac: Waiting
71a8bc8ee4a8: Pulling fs layer
6102c2ad01e7: Waiting
412dee14a042: Pulling fs layer
5d922c5d1da7: Pulling fs layer
f9aa7eff4c15: Pulling fs layer
39e9df6610b7: Pulling fs layer
71a8bc8ee4a8: Waiting
9c8a6b3b7445: Pulling fs layer
f9aa7eff4c15: Waiting
412dee14a042: Waiting
5d922c5d1da7: Waiting
25ed8948efe2: Pulling fs layer
9c8a6b3b7445: Waiting
1785ed8296b5: Pulling fs layer
25ed8948efe2: Waiting
1785ed8296b5: Waiting
8ce14f1b6040: Verifying Checksum
8ce14f1b6040: Download complete
bc3ece41e309: Verifying Checksum
bc3ece41e309: Download complete
2e1749e41102: Verifying Checksum
2e1749e41102: Download complete
09e2bc8a597c: Verifying Checksum
09e2bc8a597c: Download complete
ef83c79745fb: Download complete
e763f42586ce: Verifying Checksum
e763f42586ce: Download complete
2b9b886a42b7: Verifying Checksum
2b9b886a42b7: Download complete
c4087cb4d203: Verifying Checksum
c4087cb4d203: Download complete
22deef2c6d74: Verifying Checksum
22deef2c6d74: Download complete
7e173d175d10: Verifying Checksum
7e173d175d10: Download complete
d94d92919122: Verifying Checksum
d94d92919122: Download complete
6bb80b25c679: Verifying Checksum
6bb80b25c679: Download complete
d4d0501e8640: Download complete
09e2bc8a597c: Pull complete
4ba75a747dc2: Download complete
6f174565ecc2: Download complete
bdfba4e06563: Verifying Checksum
bdfba4e06563: Download complete
da15b734f4e0: Download complete
91d9256d1553: Download complete
425eed1469d0: Verifying Checksum
425eed1469d0: Download complete
7d025bc8d970: Download complete
00c5aaadc119: Verifying Checksum
00c5aaadc119: Download complete
a8eca5b08ab0: Verifying Checksum
a8eca5b08ab0: Download complete
bcd418f9087a: Verifying Checksum
bcd418f9087a: Download complete
339d14fa1e4c: Verifying Checksum
339d14fa1e4c: Download complete
4f4fb700ef54: Verifying Checksum
4f4fb700ef54: Download complete
5eb1a1bfa10e: Verifying Checksum
5eb1a1bfa10e: Download complete
9f5fbef0620e: Download complete
1cc816f5fb7c: Verifying Checksum
1cc816f5fb7c: Download complete
b255d9d428d8: Download complete
a78a1dc0f4ef: Verifying Checksum
a78a1dc0f4ef: Download complete
fa1002082786: Download complete
de70acc16f82: Download complete
5e97fff42a10: Verifying Checksum
5e97fff42a10: Download complete
c3b64c473cfe: Verifying Checksum
c3b64c473cfe: Download complete
81c46080858b: Verifying Checksum
81c46080858b: Download complete
c39bdad10cf5: Verifying Checksum
c39bdad10cf5: Download complete
58d9ecc6cfdb: Download complete
2b9b886a42b7: Pull complete
8ce14f1b6040: Pull complete
bc3ece41e309: Pull complete
415592e71761: Verifying Checksum
415592e71761: Download complete
2e1749e41102: Pull complete
ef83c79745fb: Pull complete
91d0d0f534d2: Download complete
4105f2da20ce: Download complete
96109d199f8e: Verifying Checksum
96109d199f8e: Download complete
def4274856d4: Verifying Checksum
def4274856d4: Download complete
ec78cb8480bd: Verifying Checksum
ec78cb8480bd: Download complete
0dbac9a3d1e0: Verifying Checksum
0dbac9a3d1e0: Download complete
4faf7f61c2dd: Verifying Checksum
4faf7f61c2dd: Download complete
86cfc42b53c3: Download complete
24bca1ad81f4: Download complete
7d6447c960f3: Verifying Checksum
7d6447c960f3: Download complete
704da0235df3: Verifying Checksum
704da0235df3: Download complete
3b0b69eb049b: Verifying Checksum
3b0b69eb049b: Download complete
537dec467165: Download complete
ff3bbbedf6ac: Download complete
51b20db66ae9: Verifying Checksum
51b20db66ae9: Download complete
dc7747ed74a7: Verifying Checksum
dc7747ed74a7: Download complete
271ae3ecbe0d: Verifying Checksum
271ae3ecbe0d: Download complete
9b987fd087da: Verifying Checksum
9b987fd087da: Download complete
fb9e55e586fa: Verifying Checksum
fb9e55e586fa: Download complete
fd4bbda75e78: Download complete
f03725552f0a: Verifying Checksum
f03725552f0a: Download complete
37ee2f377bce: Verifying Checksum
37ee2f377bce: Download complete
bb63d693d815: Verifying Checksum
bb63d693d815: Download complete
fd172d8c5862: Verifying Checksum
fd172d8c5862: Download complete
2b40fb470834: Verifying Checksum
2b40fb470834: Download complete
4e71aa62ff60: Verifying Checksum
4e71aa62ff60: Download complete
23510a6343fd: Download complete
c9f866f195f3: Verifying Checksum
c9f866f195f3: Download complete
079fdcbfbf54: Download complete
8728d7d7d7db: Verifying Checksum
8728d7d7d7db: Download complete
d7cc881e1ebb: Download complete
42809a0f6939: Download complete
32341e95c9ae: Verifying Checksum
32341e95c9ae: Download complete
14f6d686ad0e: Verifying Checksum
14f6d686ad0e: Download complete
7983115a1993: Download complete
460c6c77ab97: Verifying Checksum
460c6c77ab97: Download complete
9d81585664ac: Verifying Checksum
9d81585664ac: Download complete
9dcae794478d: Verifying Checksum
9dcae794478d: Download complete
e047a7a0ca04: Verifying Checksum
e047a7a0ca04: Download complete
6d3a284f9141: Verifying Checksum
6d3a284f9141: Download complete
5ea6df8e7a07: Verifying Checksum
5ea6df8e7a07: Download complete
0f51bfe3804f: Verifying Checksum
0f51bfe3804f: Download complete
c7c6489014d8: Download complete
8bc5ad50c954: Verifying Checksum
8bc5ad50c954: Download complete
fef2e7cb801c: Verifying Checksum
fef2e7cb801c: Download complete
5264701fb427: Verifying Checksum
5264701fb427: Download complete
59106d4298b7: Download complete
59cb04e44bd9: Download complete
6cadd8d78d75: Download complete
342d991a1373: Download complete
2d8af8ec16b4: Download complete
bda034caa3f7: Download complete
dcf44bd1bad8: Verifying Checksum
dcf44bd1bad8: Download complete
b0f2b7224b35: Download complete
ae2f82e34288: Verifying Checksum
ae2f82e34288: Download complete
bf061592f1b5: Verifying Checksum
bf061592f1b5: Download complete
f27a436e1e5f: Verifying Checksum
f27a436e1e5f: Download complete
10064aa6ffbc: Verifying Checksum
10064aa6ffbc: Download complete
7e7114afa1df: Verifying Checksum
7e7114afa1df: Download complete
d196687fcc5a: Download complete
80d88015f8e8: Verifying Checksum
80d88015f8e8: Download complete
bae910fe3da9: Verifying Checksum
bae910fe3da9: Download complete
e974a9812dac: Verifying Checksum
e974a9812dac: Download complete
71a8bc8ee4a8: Download complete
6102c2ad01e7: Verifying Checksum
6102c2ad01e7: Download complete
412dee14a042: Download complete
45036c5db557: Verifying Checksum
45036c5db557: Download complete
f9aa7eff4c15: Verifying Checksum
f9aa7eff4c15: Download complete
39e9df6610b7: Verifying Checksum
39e9df6610b7: Download complete
9c8a6b3b7445: Verifying Checksum
9c8a6b3b7445: Download complete
5d922c5d1da7: Verifying Checksum
5d922c5d1da7: Download complete
25ed8948efe2: Download complete
1785ed8296b5: Download complete
7e173d175d10: Pull complete
e763f42586ce: Pull complete
c4087cb4d203: Pull complete
6bb80b25c679: Pull complete
22deef2c6d74: Pull complete
6f174565ecc2: Pull complete
d94d92919122: Pull complete
d4d0501e8640: Pull complete
4ba75a747dc2: Pull complete
bdfba4e06563: Pull complete
da15b734f4e0: Pull complete
425eed1469d0: Pull complete
91d9256d1553: Pull complete
1cc816f5fb7c: Pull complete
bcd418f9087a: Pull complete
7d025bc8d970: Pull complete
00c5aaadc119: Pull complete
a8eca5b08ab0: Pull complete
339d14fa1e4c: Pull complete
4f4fb700ef54: Pull complete
5eb1a1bfa10e: Pull complete
415592e71761: Pull complete
9f5fbef0620e: Pull complete
a78a1dc0f4ef: Pull complete
b255d9d428d8: Pull complete
de70acc16f82: Pull complete
fa1002082786: Pull complete
c3b64c473cfe: Pull complete
5e97fff42a10: Pull complete
81c46080858b: Pull complete
c39bdad10cf5: Pull complete
2b40fb470834: Pull complete
58d9ecc6cfdb: Pull complete
4105f2da20ce: Pull complete
91d0d0f534d2: Pull complete
ec78cb8480bd: Pull complete
96109d199f8e: Pull complete
def4274856d4: Pull complete
0dbac9a3d1e0: Pull complete
86cfc42b53c3: Pull complete
4faf7f61c2dd: Pull complete
24bca1ad81f4: Pull complete
704da0235df3: Pull complete
7d6447c960f3: Pull complete
3b0b69eb049b: Pull complete
537dec467165: Pull complete
51b20db66ae9: Pull complete
ff3bbbedf6ac: Pull complete
dc7747ed74a7: Pull complete
271ae3ecbe0d: Pull complete
9b987fd087da: Pull complete
fb9e55e586fa: Pull complete
23510a6343fd: Pull complete
fd4bbda75e78: Pull complete
f03725552f0a: Pull complete
37ee2f377bce: Pull complete
bb63d693d815: Pull complete
fd172d8c5862: Pull complete
460c6c77ab97: Pull complete
4e71aa62ff60: Pull complete
c9f866f195f3: Pull complete
32341e95c9ae: Pull complete
079fdcbfbf54: Pull complete
8728d7d7d7db: Pull complete
d7cc881e1ebb: Pull complete
42809a0f6939: Pull complete
14f6d686ad0e: Pull complete
7983115a1993: Pull complete
0f51bfe3804f: Pull complete
9d81585664ac: Pull complete
342d991a1373: Pull complete
9dcae794478d: Pull complete
e047a7a0ca04: Pull complete
6d3a284f9141: Pull complete
5ea6df8e7a07: Pull complete
c7c6489014d8: Pull complete
8bc5ad50c954: Pull complete
5264701fb427: Pull complete
fef2e7cb801c: Pull complete
6cadd8d78d75: Pull complete
59106d4298b7: Pull complete
59cb04e44bd9: Pull complete
dcf44bd1bad8: Pull complete
2d8af8ec16b4: Pull complete
bda034caa3f7: Pull complete
bf061592f1b5: Pull complete
b0f2b7224b35: Pull complete
ae2f82e34288: Pull complete
10064aa6ffbc: Pull complete
f27a436e1e5f: Pull complete
80d88015f8e8: Pull complete
7e7114afa1df: Pull complete
d196687fcc5a: Pull complete
bae910fe3da9: Pull complete
e974a9812dac: Pull complete
6102c2ad01e7: Pull complete
45036c5db557: Pull complete
71a8bc8ee4a8: Pull complete
412dee14a042: Pull complete
5d922c5d1da7: Pull complete
f9aa7eff4c15: Pull complete
39e9df6610b7: Pull complete
9c8a6b3b7445: Pull complete
25ed8948efe2: Pull complete
1785ed8296b5: Pull complete
Digest: sha256:d44e872f338de09f70d9d986f16e4daf3ef531cec9699d3183f0e1e60425bd91
Status: Image is up to date for sswiston/rb_tp:7
docker.io/sswiston/rb_tp:7
/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
2024-04-03_15:37:43
RevBayes: generate island radiation rates (2)

RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2392-g9a7fd3) on Mon Mar  4 19:45:37 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "./scripts/rev_scripts/make_fig_rate_output.Rev"
   Processing file "scripts/rev_scripts/model.Rev"
   Error:	The folder doesn't exist.
   Error:	Problem processing line 17 in file "scripts/rev_scripts/model.Rev"
   Error:	Problem processing line 21 in file "./scripts/rev_scripts/make_fig_rate_output.Rev"
> RevBayes: generate Phylojunction scripts (2)
python3 ./scripts/make_pj.py 2 experiment1/geosse_rates_for_pj_scripts/ experiment1/model_truth/ experiment1/pj_scripts_generated_in_py/ 127 7 "17.750, 7.750, 6.000, 3.930, 2.100, 1.100"
Everything OK with provided arguments!
Preparing .pj script for simulation 2.
...done!
Phylojunction: simulate island radiation (2)
Matplotlib created a temporary cache directory at /tmp/201758.tmpdir/matplotlib-1a68_i45 because the default path (/home/michael.landis/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
Fontconfig error: No writable cache directories
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
Reading script ./experiment1/pj_scripts_generated_in_py/sim2.pj
    ... done!
Writing ./experiment1/pj_output/figures/sample2_trs1_1
RevBayes: simulate sequence data and make final tree (2)


RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2392-g9a7fd3) on Mon Mar  4 19:45:37 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "./scripts/rev_scripts/sim_sequences.Rev"
Working on simulation 2
root age 28.1996 colonization age 3.70164 origin time 0.429263 ingroup branch 24.9272
Got root and colonization ages
Grafted outgroup onto tree
Grafted outgroup onto tip data
   Attempting to read the contents of file "sample2.tre"
   Successfully read file
Removed extinct taxa and saved new tree
Simulated sequences
/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)
WARNING: ignoring environment value of R_HOME
During startup - Warning messages:
1: Setting LC_CTYPE failed, using "C" 
2: Setting LC_COLLATE failed, using "C" 
3: Setting LC_TIME failed, using "C" 
4: Setting LC_MESSAGES failed, using "C" 
5: Setting LC_MONETARY failed, using "C" 
6: Setting LC_PAPER failed, using "C" 
7: Setting LC_MEASUREMENT failed, using "C" 
Taxon= 1 	range_int= 6 	range_bit= 0000001 	region_set= Z 
Taxon= 2 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 3 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 4 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 5 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 6 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 7 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 8 	range_int= 8 	range_bit= 1010000 	region_set= GK 
Taxon= 9 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 10 	range_int= 98 	range_bit= 1111100 	region_set= GNKOM 
Taxon= 11 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 12 	range_int= 2 	range_bit= 0010000 	region_set= K 
Taxon= 13 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 14 	range_int= 5 	range_bit= 0000010 	region_set= H 
Taxon= 15 	range_int= 3 	range_bit= 0001000 	region_set= O 
Taxon= 16 	range_int= 3 	range_bit= 0001000 	region_set= O 
null device 
          1 

------------------------------------------------------------
Sender: LSF System <lsfadmin@compute1-exec-113.ris.wustl.edu>
Subject: Job 201758: <2> in cluster <compute1-lsf> Done

Job <2> was submitted from host <compute1-client-1.ris.wustl.edu> by user <michael.landis> in cluster <compute1-lsf> at Wed Apr  3 10:33:00 2024
Job was executed on host(s) <4*compute1-exec-113.ris.wustl.edu>, in queue <general>, as user <michael.landis> in cluster <compute1-lsf> at Wed Apr  3 10:33:06 2024
</home/michael.landis> was used as the home directory.
</storage1/fs1/michael.landis/Active/hawaiian_simulations/> was used as the working directory.
Started at Wed Apr  3 10:33:06 2024
Terminated at Wed Apr  3 10:38:03 2024
Results reported at Wed Apr  3 10:38:03 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/bin/bash /storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/sim_one.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   10.73 sec.
    Max Memory :                                 9 MB
    Average Memory :                             8.84 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               4087.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                18
    Run time :                                   297 sec.
    Turnaround time :                            303 sec.

The output (if any) is above this job summary.

