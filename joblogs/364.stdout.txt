pj: Pulling from sswiston/rb_tp
Digest: sha256:e849496dd68b3ce2754532044c538a6d681b23b262977f6a2da8deb3a9e6bf90
Status: Image is up to date for sswiston/rb_tp:pj
docker.io/sswiston/rb_tp:pj
Setting up Docker container
Performing simulation 364
2024-01-25_09:17:24
Generating PhyloJunction script

RevBayes version (1.2.1)
Build from hawaii_fix (rapture-2191-gf38548) on Fri Jan 12 23:23:51 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "/storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/rev_scripts/make_fig_make_pj_unif_coltime.Rev"
   Processing file "scripts/rev_scripts/model.Rev"
Reading features in time slice 1
Reading features in time slice 2
Reading features in time slice 3
Reading features in time slice 4
Reading features in time slice 5
Reading features in time slice 6
Reading features in time slice 7
   Processing of file "scripts/rev_scripts/model.Rev" completed

Preparing .pj script string for sample 364

Whole tree root age = 25.4281
Origin age of island radiation = 7.6248
Island that got colonized = Necker
    Doing time slice 1
      Doing extinction rates
      Doing transition rates
      Doing birth rates
    Doing time slice 2
      Doing extinction rates
      Doing transition rates
      Doing birth rates
    Doing time slice 3
      Doing extinction rates
      Doing transition rates
      Doing birth rates
    Doing time slice 4
      Doing extinction rates
      Doing transition rates
      Doing birth rates
    Doing time slice 5
      Doing extinction rates
      Doing transition rates
      Doing birth rates
    Doing time slice 6
      Doing extinction rates
      Doing transition rates
      Doing birth rates
    Doing time slice 7
      Doing extinction rates
      Doing transition rates
      Doing birth rates
Running PhyloJunction script
Matplotlib created a temporary cache directory at /tmp/820937.tmpdir/matplotlib-g5653odm because the default path (/home/k.swiston/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:456: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '7.5871' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.
  tree_summary_df_dict[rv_name].at[idx, "root_age"] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:460: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '7.6248' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.
  tree_summary_df_dict[rv_name].at[idx, "origin_age"] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:480: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
Traceback (most recent call last):
  File "/.local/bin/pjcli", line 33, in <module>
Reading script /storage1/fs1/michael.landis/Active/hawaiian_simulations/experiment1/pj_scripts/sim364.pj
    ... done!
outfile_path = /storage1/fs1/michael.landis/Active/hawaiian_simulations/experiment1/pj_output/figures/sample364_trs1_1
    sys.exit(load_entry_point('phylojunction', 'console_scripts', 'pjcli')())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/PhyloJunction/src/phylojunction/interface/pjcli/pj_cli.py", line 156, in call_cli
    execute_pj_script(
  File "/PhyloJunction/src/phylojunction/interface/pjcli/pj_cli.py", line 83, in execute_pj_script
    cliplt.call_node_plot_cli(
  File "/PhyloJunction/src/phylojunction/interface/pjcli/cli_plotting.py", line 139, in call_node_plot_cli
    selected_node_plot_cli(
  File "/PhyloJunction/src/phylojunction/interface/pjcli/cli_plotting.py", line 78, in selected_node_plot_cli
    node_pgm.plot_node(
  File "/PhyloJunction/src/phylojunction/pgm/pgm.py", line 567, in plot_node
    .plot_node(axes, node_attr=branch_attr)
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/PhyloJunction/src/phylojunction/data/tree.py", line 1035, in plot_node
    return plot_ann_tree(self, axes, attr_of_interest=node_attr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/PhyloJunction/src/phylojunction/data/tree.py", line 1571, in plot_ann_tree
    color = color_map[attr_idx]
            ~~~~~~~~~^^^^^^^^^^
KeyError: 23

RevBayes version (1.2.1)
Build from hawaii_fix (rapture-2191-gf38548) on Fri Jan 12 23:23:51 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "/storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/rev_scripts/sim_sequences.Rev"
Working on simulation 364
root age 25.4281 colonization age 7.6248 origin time 0.0376849 ingroup branch 17.841
Got root and colonization ages
Grafted outgroup onto tree
Grafted outgroup onto tip data
   Attempting to read the contents of file "sample364.tre"
   Successfully read file
Removed extinct taxa and saved new tree
Simulated sequences

------------------------------------------------------------
Sender: LSF System <lsfadmin@compute1-exec-127.ris.wustl.edu>
Subject: Job 820937: <364> in cluster <compute1-lsf> Done

Job <364> was submitted from host <compute1-client-1.ris.wustl.edu> by user <k.swiston> in cluster <compute1-lsf> at Wed Jan 24 20:04:08 2024
Job was executed on host(s) <8*compute1-exec-127.ris.wustl.edu>, in queue <general>, as user <k.swiston> in cluster <compute1-lsf> at Thu Jan 25 03:17:23 2024
</home/k.swiston> was used as the home directory.
</storage1/fs1/michael.landis/Active/hawaiian_simulations/> was used as the working directory.
Started at Thu Jan 25 03:17:23 2024
Terminated at Thu Jan 25 03:42:56 2024
Results reported at Thu Jan 25 03:42:56 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/bin/bash /storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/sim.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1193.01 sec.
    Max Memory :                                 482 MB
    Average Memory :                             283.88 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               15902.00 MB
    Max Swap :                                   474 MB
    Max Processes :                              9
    Max Threads :                                22
    Run time :                                   1533 sec.
    Turnaround time :                            27528 sec.

The output (if any) is above this job summary.

