pj: Pulling from sswiston/rb_tp
7faaa42ac0c1: Pulling fs layer
259564f9e921: Pulling fs layer
37d2c5aacb5c: Pulling fs layer
301c0f932d05: Pulling fs layer
95782daf2470: Pulling fs layer
ba90500ec825: Pulling fs layer
5fd4ea7000a4: Pulling fs layer
445c3fd9e01d: Pulling fs layer
d36f097804f7: Pulling fs layer
643f0d94093b: Pulling fs layer
99cde4c7e6cb: Pulling fs layer
9cc1f87a3101: Pulling fs layer
015b9b463ab9: Pulling fs layer
69857da9dcc9: Pulling fs layer
63a68e0fc2e0: Pulling fs layer
5fd4ea7000a4: Waiting
1e574d3851a9: Pulling fs layer
445c3fd9e01d: Waiting
d36f097804f7: Waiting
301c0f932d05: Waiting
55cb539c2eed: Pulling fs layer
519c8a896a0d: Pulling fs layer
56f84f246308: Pulling fs layer
95782daf2470: Waiting
81949ee1a8ee: Pulling fs layer
ba90500ec825: Waiting
015b9b463ab9: Waiting
a3cfbf31d985: Pulling fs layer
63a68e0fc2e0: Waiting
69857da9dcc9: Waiting
35a5697ac0f5: Pulling fs layer
1e574d3851a9: Waiting
55cb539c2eed: Waiting
9b12ca219464: Pulling fs layer
643f0d94093b: Waiting
9cc1f87a3101: Waiting
99cde4c7e6cb: Waiting
eba7b17a56c8: Pulling fs layer
56f84f246308: Waiting
a3cfbf31d985: Waiting
81949ee1a8ee: Waiting
519c8a896a0d: Waiting
35a5697ac0f5: Waiting
148190f05d4a: Pulling fs layer
9b12ca219464: Waiting
eba7b17a56c8: Waiting
bd852423970b: Pulling fs layer
148190f05d4a: Waiting
4f4fb700ef54: Pulling fs layer
bd852423970b: Waiting
2da145333255: Pulling fs layer
4f4fb700ef54: Waiting
da9f97032281: Pulling fs layer
12b9705abfb4: Pulling fs layer
3fcc9927493b: Pulling fs layer
2da145333255: Waiting
af508e4e47f0: Pulling fs layer
12b9705abfb4: Waiting
da9f97032281: Waiting
3fcc9927493b: Waiting
af508e4e47f0: Waiting
e2633376ca26: Pulling fs layer
6a094d88136e: Pulling fs layer
add382e10c9c: Pulling fs layer
30355687ee93: Pulling fs layer
e2633376ca26: Waiting
3379f6ca3f28: Pulling fs layer
6a094d88136e: Waiting
30355687ee93: Waiting
fe692bbcc5b1: Pulling fs layer
add382e10c9c: Waiting
0220f7630717: Pulling fs layer
fe692bbcc5b1: Waiting
3379f6ca3f28: Waiting
5e7700541479: Pulling fs layer
0220f7630717: Waiting
206cdb7fce28: Pulling fs layer
5e7700541479: Waiting
63a32f058a1e: Pulling fs layer
206cdb7fce28: Waiting
34f2e3e1cc9a: Pulling fs layer
63a32f058a1e: Waiting
996a20b9df68: Pulling fs layer
34f2e3e1cc9a: Waiting
6997756d443c: Pulling fs layer
eeb88d7643cc: Pulling fs layer
6997756d443c: Waiting
ce1a77a6dcc7: Pulling fs layer
a67f053877c6: Pulling fs layer
6d4603ba01f6: Pulling fs layer
ec5984c59fae: Pulling fs layer
eeb88d7643cc: Waiting
ce1a77a6dcc7: Waiting
ec5984c59fae: Waiting
6d4603ba01f6: Waiting
a67f053877c6: Waiting
37d2c5aacb5c: Verifying Checksum
37d2c5aacb5c: Download complete
301c0f932d05: Verifying Checksum
301c0f932d05: Download complete
95782daf2470: Download complete
7faaa42ac0c1: Verifying Checksum
7faaa42ac0c1: Download complete
259564f9e921: Verifying Checksum
259564f9e921: Download complete
445c3fd9e01d: Verifying Checksum
445c3fd9e01d: Download complete
d36f097804f7: Download complete
5fd4ea7000a4: Download complete
643f0d94093b: Download complete
ba90500ec825: Verifying Checksum
ba90500ec825: Download complete
9cc1f87a3101: Verifying Checksum
9cc1f87a3101: Download complete
015b9b463ab9: Download complete
69857da9dcc9: Verifying Checksum
69857da9dcc9: Download complete
63a68e0fc2e0: Verifying Checksum
63a68e0fc2e0: Download complete
1e574d3851a9: Download complete
519c8a896a0d: Verifying Checksum
519c8a896a0d: Download complete
55cb539c2eed: Download complete
99cde4c7e6cb: Verifying Checksum
99cde4c7e6cb: Download complete
56f84f246308: Verifying Checksum
56f84f246308: Download complete
7faaa42ac0c1: Pull complete
81949ee1a8ee: Verifying Checksum
81949ee1a8ee: Download complete
35a5697ac0f5: Verifying Checksum
35a5697ac0f5: Download complete
9b12ca219464: Verifying Checksum
9b12ca219464: Download complete
eba7b17a56c8: Verifying Checksum
eba7b17a56c8: Download complete
148190f05d4a: Verifying Checksum
148190f05d4a: Download complete
4f4fb700ef54: Download complete
a3cfbf31d985: Verifying Checksum
a3cfbf31d985: Download complete
2da145333255: Verifying Checksum
2da145333255: Download complete
bd852423970b: Verifying Checksum
bd852423970b: Download complete
12b9705abfb4: Verifying Checksum
12b9705abfb4: Download complete
3fcc9927493b: Verifying Checksum
3fcc9927493b: Download complete
af508e4e47f0: Download complete
e2633376ca26: Verifying Checksum
e2633376ca26: Download complete
6a094d88136e: Download complete
add382e10c9c: Download complete
30355687ee93: Verifying Checksum
30355687ee93: Download complete
fe692bbcc5b1: Verifying Checksum
da9f97032281: Verifying Checksum
da9f97032281: Download complete
0220f7630717: Verifying Checksum
0220f7630717: Download complete
5e7700541479: Verifying Checksum
5e7700541479: Download complete
206cdb7fce28: Verifying Checksum
206cdb7fce28: Download complete
63a32f058a1e: Verifying Checksum
63a32f058a1e: Download complete
259564f9e921: Pull complete
37d2c5aacb5c: Pull complete
301c0f932d05: Pull complete
95782daf2470: Pull complete
996a20b9df68: Verifying Checksum
996a20b9df68: Download complete
3379f6ca3f28: Verifying Checksum
3379f6ca3f28: Download complete
6997756d443c: Verifying Checksum
6997756d443c: Download complete
34f2e3e1cc9a: Verifying Checksum
34f2e3e1cc9a: Download complete
ce1a77a6dcc7: Verifying Checksum
ce1a77a6dcc7: Download complete
a67f053877c6: Download complete
6d4603ba01f6: Download complete
ec5984c59fae: Download complete
eeb88d7643cc: Verifying Checksum
eeb88d7643cc: Download complete
ba90500ec825: Pull complete
5fd4ea7000a4: Pull complete
445c3fd9e01d: Pull complete
d36f097804f7: Pull complete
643f0d94093b: Pull complete
99cde4c7e6cb: Pull complete
9cc1f87a3101: Pull complete
015b9b463ab9: Pull complete
69857da9dcc9: Pull complete
63a68e0fc2e0: Pull complete
1e574d3851a9: Pull complete
55cb539c2eed: Pull complete
519c8a896a0d: Pull complete
56f84f246308: Pull complete
81949ee1a8ee: Pull complete
a3cfbf31d985: Pull complete
35a5697ac0f5: Pull complete
9b12ca219464: Pull complete
eba7b17a56c8: Pull complete
148190f05d4a: Pull complete
bd852423970b: Pull complete
4f4fb700ef54: Pull complete
2da145333255: Pull complete
da9f97032281: Pull complete
12b9705abfb4: Pull complete
3fcc9927493b: Pull complete
af508e4e47f0: Pull complete
e2633376ca26: Pull complete
6a094d88136e: Pull complete
add382e10c9c: Pull complete
30355687ee93: Pull complete
3379f6ca3f28: Pull complete
fe692bbcc5b1: Pull complete
0220f7630717: Pull complete
5e7700541479: Pull complete
206cdb7fce28: Pull complete
63a32f058a1e: Pull complete
34f2e3e1cc9a: Pull complete
996a20b9df68: Pull complete
6997756d443c: Pull complete
eeb88d7643cc: Pull complete
ce1a77a6dcc7: Pull complete
a67f053877c6: Pull complete
6d4603ba01f6: Pull complete
ec5984c59fae: Pull complete
Digest: sha256:8a960c0d392cc6c08aa640ba8b624d29c9316f2a483b87b8908f3083062a233b
Status: Downloaded newer image for sswiston/rb_tp:pj
docker.io/sswiston/rb_tp:pj
Setting up Docker container
Performing simulation 68
2024-02-07_09:21:28
Generating model parameters

RevBayes version (1.2.1)
Build from hawaii_fix (rapture-2191-gf38548) on Wed Feb  7 01:25:36 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "/storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/rev_scripts/make_fig_make_geosse_rates_unif_coltime.Rev"
   Processing file "scripts/rev_scripts/model.Rev"
Reading features in time slice 1
Reading features in time slice 2
Reading features in time slice 3
Reading features in time slice 4
Reading features in time slice 5
Reading features in time slice 6
Reading features in time slice 7
   Processing of file "scripts/rev_scripts/model.Rev" completed
Setting seed to 68
Writing true feature effect values for categorical feature 1 in /storage1/fs1/michael.landis/Active/hawaiian_simulations/experiment1/model_truth/sigma_true_vals_sample68_feat1.tsv
Writing true feature effect values for quantitative feature 1 in /storage1/fs1/michael.landis/Active/hawaiian_simulations/experiment1/model_truth/phi_true_vals_sample68_feat1.tsv
Writing true base rate values for sample 68 in /storage1/fs1/michael.landis/Active/hawaiian_simulations/experiment1/model_truth/rho_true_vals_sample68.tsv

Whole tree root age = 16.44
Origin age of island radiation = 13.0937
Island that got colonized = Gardener
Generating PhyloJunction script
Everything OK with provided arguments!
Preparing .pj script for simulation 68.
...done!
Running PhyloJunction script
Matplotlib created a temporary cache directory at /tmp/224423.tmpdir/matplotlib-ck78br36 because the default path (/home/k.swiston/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:455: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.9788' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.
  tree_summary_df_dict[rv_name].at[idx, "root_age"] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:459: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13.0937' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.
  tree_summary_df_dict[rv_name].at[idx, "origin_age"] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
Reading script /storage1/fs1/michael.landis/Active/hawaiian_simulations/experiment1/pj_scripts_generated_in_py/sim68.pj
    ... done!
outfile_path = /storage1/fs1/michael.landis/Active/hawaiian_simulations/experiment1/pj_output/figures/sample68_trs1_1

RevBayes version (1.2.1)
Build from hawaii_fix (rapture-2191-gf38548) on Wed Feb  7 01:25:36 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "/storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/rev_scripts/sim_sequences.Rev"
Working on simulation 68
root age 16.44 colonization age 13.0937 origin time 2.1149 ingroup branch 5.4612
Got root and colonization ages
Grafted outgroup onto tree
Grafted outgroup onto tip data
   Attempting to read the contents of file "sample68.tre"
   Successfully read file
Removed extinct taxa and saved new tree
Simulated sequences

------------------------------------------------------------
Sender: LSF System <lsfadmin@compute1-exec-41.ris.wustl.edu>
Subject: Job 224423: <68> in cluster <compute1-lsf> Done

Job <68> was submitted from host <compute1-client-1.ris.wustl.edu> by user <k.swiston> in cluster <compute1-lsf> at Tue Feb  6 22:03:48 2024
Job was executed on host(s) <4*compute1-exec-41.ris.wustl.edu>, in queue <general>, as user <k.swiston> in cluster <compute1-lsf> at Wed Feb  7 03:19:56 2024
</home/k.swiston> was used as the home directory.
</storage1/fs1/michael.landis/Active/hawaiian_simulations/> was used as the working directory.
Started at Wed Feb  7 03:19:56 2024
Terminated at Wed Feb  7 03:21:47 2024
Results reported at Wed Feb  7 03:21:47 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/bin/bash /storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/sim.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   10.37 sec.
    Max Memory :                                 9 MB
    Average Memory :                             8.65 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               4087.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                15
    Run time :                                   111 sec.
    Turnaround time :                            19079 sec.

The output (if any) is above this job summary.

pj: Pulling from sswiston/rb_tp
Digest: sha256:6fbf4ccd7a9b854cf2f7d855afca38f7eaa0ee4f0f0179737b55b78f1c8d30ff
Status: Image is up to date for sswiston/rb_tp:pj
docker.io/sswiston/rb_tp:pj
Setting up Docker container
Performing simulation 68
2024-02-15_16:57:32
Generating model parameters

RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2386-gf9f25c) on Thu Feb  8 16:07:25 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "/storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/rev_scripts/make_fig_make_geosse_rates_unif_coltime.Rev"
   Processing file "scripts/rev_scripts/model.Rev"
   Error:	The folder doesn't exist.
   Error:	Problem processing line 17 in file "scripts/rev_scripts/model.Rev"
   Error:	Problem processing line 21 in file
   "/storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/rev_scripts/make_fig_make_geosse_rates_unif_coltime.Rev"
> Generating PhyloJunction script
Everything OK with provided arguments!
Preparing .pj script for simulation 68.
...done!
Running PhyloJunction script
Matplotlib created a temporary cache directory at /tmp/421408.tmpdir/matplotlib-vwocaz5d because the default path (/home/k.swiston/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:455: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10.9788' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.
  tree_summary_df_dict[rv_name].at[idx, "root_age"] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:459: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13.0937' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.
  tree_summary_df_dict[rv_name].at[idx, "origin_age"] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
/PhyloJunction/src/phylojunction/readwrite/pj_write.py:479: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`
  tree_summary_df_dict[rv_name].at[idx, "n_" + str(ith_state)] = \
Reading script /storage1/fs1/michael.landis/Active/hawaiian_simulations/experiment1/pj_scripts_generated_in_py/sim68.pj
    ... done!
outfile_path = /storage1/fs1/michael.landis/Active/hawaiian_simulations/experiment1/pj_output/figures/sample68_trs1_1

RevBayes version (1.2.2)
Build from stochmap_tp_dirty_merge (rapture-2386-gf9f25c) on Thu Feb  8 16:07:25 UTC 2024

Visit the website www.RevBayes.com for more information about RevBayes.

RevBayes is free software released under the GPL license, version 3. Type 'license()' for details.

To quit RevBayes type 'quit()' or 'q()'.


>    Processing file "/storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/rev_scripts/sim_sequences.Rev"
Working on simulation 68
root age 16.44 colonization age 13.0937 origin time 2.1149 ingroup branch 5.4612
Got root and colonization ages
Grafted outgroup onto tree
Grafted outgroup onto tip data
   Attempting to read the contents of file "sample68.tre"
   Successfully read file
Removed extinct taxa and saved new tree
Simulated sequences

------------------------------------------------------------
Sender: LSF System <lsfadmin@compute1-exec-170.ris.wustl.edu>
Subject: Job 421408: <68> in cluster <compute1-lsf> Done

Job <68> was submitted from host <compute1-client-1.ris.wustl.edu> by user <k.swiston> in cluster <compute1-lsf> at Thu Feb 15 10:21:28 2024
Job was executed on host(s) <4*compute1-exec-170.ris.wustl.edu>, in queue <general>, as user <k.swiston> in cluster <compute1-lsf> at Thu Feb 15 10:57:31 2024
</home/k.swiston> was used as the home directory.
</storage1/fs1/michael.landis/Active/hawaiian_simulations/> was used as the working directory.
Started at Thu Feb 15 10:57:31 2024
Terminated at Thu Feb 15 10:57:49 2024
Results reported at Thu Feb 15 10:57:49 2024

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/bin/bash /storage1/fs1/michael.landis/Active/hawaiian_simulations/scripts/sim.sh
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   13.19 sec.
    Max Memory :                                 142 MB
    Average Memory :                             105.50 MB
    Total Requested Memory :                     4096.00 MB
    Delta Memory :                               3954.00 MB
    Max Swap :                                   134 MB
    Max Processes :                              9
    Max Threads :                                13
    Run time :                                   18 sec.
    Turnaround time :                            2181 sec.

The output (if any) is above this job summary.

